{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7149c59-28a8-4bde-8729-50d501a167ff",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.telemetry.telemetry_logging:SageMaker Python SDK will collect telemetry to help us better understand our user's needs, diagnose issues, and deliver additional features.\n",
      "To opt out of telemetry, please disable via TelemetryOptOut parameter in SDK defaults config. For more information, refer to https://sagemaker.readthedocs.io/en/stable/overview.html#configuring-and-using-defaults-with-the-sagemaker-python-sdk.\n",
      "INFO:sagemaker.image_uris:image_uri is not presented, retrieving image_uri based on instance_type, framework etc.\n",
      "INFO:sagemaker.image_uris:image_uri is not presented, retrieving image_uri based on instance_type, framework etc.\n",
      "INFO:sagemaker:Creating training-job with name: pytorch-training-2025-07-20-17-46-54-991\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-20 17:46:56 Starting - Starting the training job...\n",
      "2025-07-20 17:47:10 Starting - Preparing the instances for training...\n",
      "2025-07-20 17:47:59 Downloading - Downloading the training image.."
     ]
    }
   ],
   "source": [
    "# In your SageMaker Notebook cell:\n",
    "import sagemaker\n",
    "from sagemaker.pytorch import PyTorch\n",
    "import os\n",
    "\n",
    "# --- 1. Define SageMaker Session, Role, and S3 Bucket ---\n",
    "sess = sagemaker.Session()\n",
    "role = sagemaker.get_execution_role() # IAM role with SageMaker permissions\n",
    "s3_output_bucket = \"spajjuri-transformers\" # The default S3 bucket for this SageMaker session\n",
    "\n",
    "# Define your S3 output path for model artifacts and other job outputs\n",
    "# SageMaker will upload the contents of SM_MODEL_DIR and SM_OUTPUT_DATA_DIR here.\n",
    "s3_job_output_prefix = \"transformer-model-v2-training-job\" # Unique prefix for this training job\n",
    "s3_output_uri = f\"s3://{s3_output_bucket}/{s3_job_output_prefix}\"\n",
    "\n",
    "\n",
    "# --- 2. Configure PyTorch Estimator for Managed Spot Training ---\n",
    "estimator = PyTorch(\n",
    "    entry_point='run.py',        # Your main training script\n",
    "    source_dir='./my_transformer_code',               # Directory containing train.py, model.py, dataset.py, inference.py\n",
    "                                   # SageMaker will automatically zip and upload this directory to S3.\n",
    "    role=role,                     # IAM role for the training job\n",
    "    framework_version='2.1',       # PyTorch version used in your script\n",
    "    py_version='py310',            # Python version\n",
    "    instance_count=1,              # Number of instances (for single GPU)\n",
    "    instance_type='ml.g4dn.xlarge', # The instance type you want to use (e.g., with T4 GPU)\n",
    "    output_path=s3_output_uri,     # S3 path where model artifacts will be saved after job completes\n",
    "\n",
    "    # --- Managed Spot Training Configuration ---\n",
    "    use_spot_instances=True,       # Enable Managed Spot Training\n",
    "    max_run=3 * 3600,              # Max run time in seconds (e.g., 3 hours for entire job)\n",
    "                                   # SageMaker will stop the job after this time, whether interrupted or not.\n",
    "    max_wait=6 * 3600,             # Max wait time in seconds for a Spot instance (e.g., 6 hours)\n",
    "                                   # If an instance isn't available within max_wait, the job fails.\n",
    "    \n",
    "    # --- Checkpoint Configuration (CRUCIAL for resuming interrupted Spot jobs) ---\n",
    "    # This S3 URI specifies where SageMaker will store/retrieve checkpoints.\n",
    "    # It must be within the same region as your training job.\n",
    "    checkpoint_s3_uri=f\"s3://{s3_output_bucket}/{s3_job_output_prefix}/checkpoints\", \n",
    "    # checkpoint_s3_uri = None,\n",
    "    # --- Hyperparameters to pass to your script ---\n",
    "    # These will be passed as command-line arguments to train.py\n",
    "    hyperparameters={\n",
    "        'num-epochs': 200, # A more realistic number of epochs for Multi30k\n",
    "        'batch-size': 128,\n",
    "        'embed-size': 512,\n",
    "        'num-layers': 6,\n",
    "        'forward-expansion': 4,\n",
    "        'heads': 8,\n",
    "        'dropout': 0.1, # Recommended dropout for Transformers\n",
    "        'max-length': 256,\n",
    "        'lr': 0.001,\n",
    "        'warmup-steps': 4000,\n",
    "        'clip': 5.0,\n",
    "    },\n",
    "    disable_output_compression=False # Optional: keeps logs in S3 readable (not gzipped)\n",
    ")\n",
    "\n",
    "# --- 3. Start the training job ---\n",
    "# For Multi30k, which downloads its own data, you might not need to specify a data input channel here.\n",
    "# If you had data on S3 (e.g., `s3://my-data-bucket/multi30k/`), you'd provide it as:\n",
    "# estimator.fit({'training': 's3://my-data-bucket/multi30k/'})\n",
    "estimator.fit() \n",
    "\n",
    "# After the job completes, you can inspect the outputs in S3:\n",
    "print(f\"Training job outputs will be in: {s3_output_uri}\")\n",
    "# To retrieve the model artifact (e.g., for inference):\n",
    "# trained_model_path = estimator.model_data\n",
    "# print(f\"Trained model artifacts are in: {trained_model_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52b84dd9-64e6-4209-83e1-a09d83f505c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e63c89fc-582b-4e85-afaf-d6db811240c8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p310",
   "language": "python",
   "name": "conda_pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
