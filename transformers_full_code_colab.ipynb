{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KqD8b-3XNoKb",
        "outputId": "7a8e9669-99f0-4311-da9c-81d5d2677923"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Current Working Directory: /content/drive/My Drive/Colab Notebooks\n",
            "['Untitled0.ipynb', 'LLM_Codes', 'Copy of Lab2.ipynb', '20230802_Lab_3_fine_tune_model_to_detoxify_summaries_submission.ipynb', 'Untitled', 'Untitled1.ipynb', 'HW2_Pyspark.ipynb', 'Untitled2.ipynb', 'CIFAR10_CNN.ipynb', 'CNN_CatsDogs.ipynb', 'CNN_DogsCats.ipynb', 'Untitled3.ipynb', 'Untitled4.ipynb', 'TL2.ipynb', 'PA2_Purhar.ipynb', 'PA2_submission1.ipynb', 'Chikki_Ass.ipynb', 'models', 'transformers_v2.ipynb', 'MLAssignment4.ipynb', 'Untitled5.ipynb', 'MyResume_Chatbot.ipynb', 'best_transformer_model.pth', 'transformers_full_code.ipynb']\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import os\n",
        "os.chdir(\"/content/drive/My Drive/Colab Notebooks\")  # Change directory to your folder\n",
        "\n",
        "# Verify it's correctly set\n",
        "print(\"Current Working Directory:\", os.getcwd())\n",
        "\n",
        "# List files to check if scripts are accessible\n",
        "print(os.listdir(\".\"))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!pip install torchtext==0.16.0 --no-cache-dir\n",
        "!python -m spacy download de_core_news_sm\n",
        "!python -m spacy download en_core_news_sm\n",
        "!pip install sacrebleu\n",
        "!pip install --upgrade --force-reinstall portalocker"
      ],
      "metadata": {
        "id": "YoBq61T_OPqf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e9905345-8688-4742-d2fa-2102ad1f071e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchtext==0.16.0\n",
            "  Downloading torchtext-0.16.0-cp311-cp311-manylinux1_x86_64.whl.metadata (7.5 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from torchtext==0.16.0) (4.67.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torchtext==0.16.0) (2.32.3)\n",
            "Collecting torch==2.1.0 (from torchtext==0.16.0)\n",
            "  Downloading torch-2.1.0-cp311-cp311-manylinux1_x86_64.whl.metadata (25 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchtext==0.16.0) (2.0.2)\n",
            "Collecting torchdata==0.7.0 (from torchtext==0.16.0)\n",
            "  Downloading torchdata-0.7.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch==2.1.0->torchtext==0.16.0) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from torch==2.1.0->torchtext==0.16.0) (4.14.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch==2.1.0->torchtext==0.16.0) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.1.0->torchtext==0.16.0) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch==2.1.0->torchtext==0.16.0) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch==2.1.0->torchtext==0.16.0) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch==2.1.0->torchtext==0.16.0)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch==2.1.0->torchtext==0.16.0)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch==2.1.0->torchtext==0.16.0)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch==2.1.0->torchtext==0.16.0)\n",
            "  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch==2.1.0->torchtext==0.16.0)\n",
            "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch==2.1.0->torchtext==0.16.0)\n",
            "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch==2.1.0->torchtext==0.16.0)\n",
            "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch==2.1.0->torchtext==0.16.0)\n",
            "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch==2.1.0->torchtext==0.16.0)\n",
            "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nccl-cu12==2.18.1 (from torch==2.1.0->torchtext==0.16.0)\n",
            "  Downloading nvidia_nccl_cu12-2.18.1-py3-none-manylinux1_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch==2.1.0->torchtext==0.16.0)\n",
            "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting triton==2.1.0 (from torch==2.1.0->torchtext==0.16.0)\n",
            "  Downloading triton-2.1.0-0-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.3 kB)\n",
            "Requirement already satisfied: urllib3>=1.25 in /usr/local/lib/python3.11/dist-packages (from torchdata==0.7.0->torchtext==0.16.0) (2.4.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.1.0->torchtext==0.16.0) (12.5.82)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torchtext==0.16.0) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torchtext==0.16.0) (3.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->torchtext==0.16.0) (2025.7.14)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch==2.1.0->torchtext==0.16.0) (3.0.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->torch==2.1.0->torchtext==0.16.0) (1.3.0)\n",
            "Downloading torchtext-0.16.0-cp311-cp311-manylinux1_x86_64.whl (2.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m33.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torch-2.1.0-cp311-cp311-manylinux1_x86_64.whl (670.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m670.2/670.2 MB\u001b[0m \u001b[31m113.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchdata-0.7.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.7/4.7 MB\u001b[0m \u001b[31m76.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m201.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m175.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m223.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m187.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m134.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m190.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m154.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m105.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m133.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nccl_cu12-2.18.1-py3-none-manylinux1_x86_64.whl (209.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.8/209.8 MB\u001b[0m \u001b[31m133.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m174.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading triton-2.1.0-0-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.2/89.2 MB\u001b[0m \u001b[31m149.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: triton, nvidia-nvtx-cu12, nvidia-nccl-cu12, nvidia-cusparse-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusolver-cu12, nvidia-cudnn-cu12, torch, torchdata, torchtext\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 3.2.0\n",
            "    Uninstalling triton-3.2.0:\n",
            "      Successfully uninstalled triton-3.2.0\n",
            "  Attempting uninstall: nvidia-nvtx-cu12\n",
            "    Found existing installation: nvidia-nvtx-cu12 12.4.127\n",
            "    Uninstalling nvidia-nvtx-cu12-12.4.127:\n",
            "      Successfully uninstalled nvidia-nvtx-cu12-12.4.127\n",
            "  Attempting uninstall: nvidia-nccl-cu12\n",
            "    Found existing installation: nvidia-nccl-cu12 2.21.5\n",
            "    Uninstalling nvidia-nccl-cu12-2.21.5:\n",
            "      Successfully uninstalled nvidia-nccl-cu12-2.21.5\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.6.0+cu124\n",
            "    Uninstalling torch-2.6.0+cu124:\n",
            "      Successfully uninstalled torch-2.6.0+cu124\n",
            "  Attempting uninstall: torchdata\n",
            "    Found existing installation: torchdata 0.11.0\n",
            "    Uninstalling torchdata-0.11.0:\n",
            "      Successfully uninstalled torchdata-0.11.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchtune 0.6.1 requires torchdata==0.11.0, but you have torchdata 0.7.0 which is incompatible.\n",
            "libraft-cu12 25.6.0 requires nvidia-nccl-cu12>=2.19, but you have nvidia-nccl-cu12 2.18.1 which is incompatible.\n",
            "torchvision 0.21.0+cu124 requires torch==2.6.0, but you have torch 2.1.0 which is incompatible.\n",
            "libcuvs-cu12 25.6.1 requires nvidia-nccl-cu12>=2.19, but you have nvidia-nccl-cu12 2.18.1 which is incompatible.\n",
            "torchaudio 2.6.0+cu124 requires torch==2.6.0, but you have torch 2.1.0 which is incompatible.\n",
            "raft-dask-cu12 25.6.0 requires nvidia-nccl-cu12>=2.19, but you have nvidia-nccl-cu12 2.18.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.18.1 nvidia-nvtx-cu12-12.1.105 torch-2.1.0 torchdata-0.7.0 torchtext-0.16.0 triton-2.1.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "torch",
                  "torchgen"
                ]
              },
              "id": "42818e24b7304f82bb73153ac7c453d1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "A module that was compiled using NumPy 1.x cannot be run in\n",
            "NumPy 2.0.2 as it may crash. To support both 1.x and 2.x\n",
            "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
            "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
            "\n",
            "If you are a user of the module, the easiest solution will be to\n",
            "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
            "We expect that some modules will need time to support NumPy 2.\n",
            "\n",
            "Traceback (most recent call last):  File \"<frozen runpy>\", line 189, in _run_module_as_main\n",
            "  File \"<frozen runpy>\", line 148, in _get_module_details\n",
            "  File \"<frozen runpy>\", line 112, in _get_module_details\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/spacy/__init__.py\", line 6, in <module>\n",
            "    from .errors import setup_default_warnings\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/spacy/errors.py\", line 3, in <module>\n",
            "    from .compat import Literal\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/spacy/compat.py\", line 4, in <module>\n",
            "    from thinc.util import copy_array\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/thinc/__init__.py\", line 5, in <module>\n",
            "    from .config import registry\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/thinc/config.py\", line 5, in <module>\n",
            "    from .types import Decorator\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/thinc/types.py\", line 27, in <module>\n",
            "    from .compat import cupy, has_cupy\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/thinc/compat.py\", line 35, in <module>\n",
            "    import torch\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/__init__.py\", line 1382, in <module>\n",
            "    from .functional import *  # noqa: F403\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/functional.py\", line 7, in <module>\n",
            "    import torch.nn.functional as F\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/__init__.py\", line 1, in <module>\n",
            "    from .modules import *  # noqa: F403\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/__init__.py\", line 35, in <module>\n",
            "    from .transformer import TransformerEncoder, TransformerDecoder, \\\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py\", line 20, in <module>\n",
            "    device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:84.)\n",
            "  device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
            "Collecting de-core-news-sm==3.8.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/de_core_news_sm-3.8.0/de_core_news_sm-3.8.0-py3-none-any.whl (14.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.6/14.6 MB\u001b[0m \u001b[31m62.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: de-core-news-sm\n",
            "Successfully installed de-core-news-sm-3.8.0\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('de_core_news_sm')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n",
            "\n",
            "A module that was compiled using NumPy 1.x cannot be run in\n",
            "NumPy 2.0.2 as it may crash. To support both 1.x and 2.x\n",
            "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
            "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
            "\n",
            "If you are a user of the module, the easiest solution will be to\n",
            "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
            "We expect that some modules will need time to support NumPy 2.\n",
            "\n",
            "Traceback (most recent call last):  File \"<frozen runpy>\", line 189, in _run_module_as_main\n",
            "  File \"<frozen runpy>\", line 148, in _get_module_details\n",
            "  File \"<frozen runpy>\", line 112, in _get_module_details\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/spacy/__init__.py\", line 6, in <module>\n",
            "    from .errors import setup_default_warnings\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/spacy/errors.py\", line 3, in <module>\n",
            "    from .compat import Literal\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/spacy/compat.py\", line 4, in <module>\n",
            "    from thinc.util import copy_array\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/thinc/__init__.py\", line 5, in <module>\n",
            "    from .config import registry\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/thinc/config.py\", line 5, in <module>\n",
            "    from .types import Decorator\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/thinc/types.py\", line 27, in <module>\n",
            "    from .compat import cupy, has_cupy\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/thinc/compat.py\", line 35, in <module>\n",
            "    import torch\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/__init__.py\", line 1382, in <module>\n",
            "    from .functional import *  # noqa: F403\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/functional.py\", line 7, in <module>\n",
            "    import torch.nn.functional as F\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/__init__.py\", line 1, in <module>\n",
            "    from .modules import *  # noqa: F403\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/__init__.py\", line 35, in <module>\n",
            "    from .transformer import TransformerEncoder, TransformerDecoder, \\\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py\", line 20, in <module>\n",
            "    device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:84.)\n",
            "  device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
            "\n",
            "\u001b[38;5;1m✘ No compatible package found for 'en_core_news_sm' (spaCy v3.8.7)\u001b[0m\n",
            "\n",
            "Collecting sacrebleu\n",
            "  Downloading sacrebleu-2.5.1-py3-none-any.whl.metadata (51 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.8/51.8 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting portalocker (from sacrebleu)\n",
            "  Downloading portalocker-3.2.0-py3-none-any.whl.metadata (8.7 kB)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.11/dist-packages (from sacrebleu) (2024.11.6)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.11/dist-packages (from sacrebleu) (0.9.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from sacrebleu) (2.0.2)\n",
            "Collecting colorama (from sacrebleu)\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.11/dist-packages (from sacrebleu) (5.4.0)\n",
            "Downloading sacrebleu-2.5.1-py3-none-any.whl (104 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.1/104.1 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Downloading portalocker-3.2.0-py3-none-any.whl (22 kB)\n",
            "Installing collected packages: portalocker, colorama, sacrebleu\n",
            "Successfully installed colorama-0.4.6 portalocker-3.2.0 sacrebleu-2.5.1\n",
            "Collecting portalocker\n",
            "  Using cached portalocker-3.2.0-py3-none-any.whl.metadata (8.7 kB)\n",
            "Using cached portalocker-3.2.0-py3-none-any.whl (22 kB)\n",
            "Installing collected packages: portalocker\n",
            "  Attempting uninstall: portalocker\n",
            "    Found existing installation: portalocker 3.2.0\n",
            "    Uninstalling portalocker-3.2.0:\n",
            "      Successfully uninstalled portalocker-3.2.0\n",
            "Successfully installed portalocker-3.2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4AeO9D_FOWSt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchtext.data.utils import get_tokenizer\n",
        "from torchtext.vocab import build_vocab_from_iterator\n",
        "from torchtext.datasets import Multi30k\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "import random\n",
        "import sys\n",
        "import time\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from torchtext.data.metrics import bleu_score"
      ],
      "metadata": {
        "id": "SMdXQ-q_OLa3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(torch.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b5M25lveO3-f",
        "outputId": "33390daf-3451-4256-82b0-953fe29bfc1a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.1.0+cu121\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "\"\"\"\n",
        "For understanding purpose lets take \"Cat Loves Milk\" as an input instance in the first batch of 32 samples\n",
        "\n",
        "Let's assume:\n",
        "\n",
        "Batch size (N) = 32\n",
        "1st Sentence: \"Cat Loves Milk\"\n",
        "Number of words (seq_len) = 24 (max_len of a sentence in the batch)\n",
        "Encoder\n",
        "   Input: ([<bos>,\"Cat\", \"Loves\", \"Milk\",<eos> , <pad>,....]) -> value_len = key_len = query_len = max_len = 24\n",
        "Decoder\n",
        "   Input: ([<bos>,\"Katze\", \"liebt\", \"Milch\", <pad>,....]) -> value_len = key_len = query_len = max_len = 23 NO <eos> ONLY <bos>\n",
        "   Target: ([\"Katze\", \"liebt\", \"Milch\", <eos>, <pad>, ...]) -> value_len = key_len = query_len = max_len = 23 NO <bos> ONLY <eos>\n",
        "   i.e. a shift of token happens for decoder to predict the next word which is the target\n",
        "\n",
        "Embedding size (embed_size) = 512\n",
        "Number of heads (heads) = 8\n",
        "Head dimension (head_dim) = embed_size / heads = 512 / 8 = 64\n",
        "\"\"\"\n",
        "\n",
        "class SelfAttention(nn.Module):\n",
        "    def __init__(self, embed_size, heads):\n",
        "        super().__init__()\n",
        "        self.embed_size = embed_size\n",
        "        self.heads = heads\n",
        "        self.head_dim = embed_size//heads\n",
        "\n",
        "        assert(self.head_dim * heads == embed_size), \"Embed size needs to be div by heads\"\n",
        "\n",
        "        # Each of these is a learnable weight matrix\n",
        "        self.values = nn.Linear(embed_size, embed_size) # W_V (512*512 Matrix)\n",
        "        self.keys = nn.Linear(embed_size, embed_size) # W_K (512*512 Matrix)\n",
        "        self.queries = nn.Linear(embed_size, embed_size) # W_Q (512*512 Matrix)\n",
        "        self.fc_out = nn.Linear(embed_size, embed_size) # W_O (512*512 Matrix)\n",
        "\n",
        "    def forward(self, values, keys, query, mask):\n",
        "        N = query.shape[0] # Number of Training Examples -> N = 32 in our case\n",
        "        value_len, key_len, query_len = values.shape[1], keys.shape[1], query.shape[1]  # 24 (23 when self attention called in Decoder) each sample length in the batch\n",
        "        # Difference in Query shape and key,value shape by 1 is observed when the attention is called in Decoder AFTER masked multi head self attention i.e. at cross attention\n",
        "\n",
        "        values = self.values(values)   # (N, value_len, embed_size) # (32, 24, 512) -> (32, 24, 512)\n",
        "        keys = self.keys(keys)  # (N, key_len, embed_size)  # (32, 24, 512) -> (32, 24, 512)\n",
        "        queries = self.queries(query)   # (N, query_len, embed_size)  # (32, 24 or (23 @cross atention), 512) -> (32, 24 or (23), 512)\n",
        "\n",
        "\n",
        "        # Reshape into multiple heads\n",
        "        values = values.reshape(N, value_len, self.heads, self.head_dim) # (32, 24, 8 , 64) nvhd\n",
        "        keys = keys.reshape(N, key_len, self.heads, self.head_dim) # (32, 24, 8 , 64) nkhd\n",
        "        queries = queries.reshape(N, query_len, self.heads, self.head_dim) # (32, 24, 8 , 64) nqhd\n",
        "\n",
        "\n",
        "        # Einsum does matrix multiplication. for query*keys for each training example\n",
        "        energy = torch.einsum(\"nqhd,nkhd -> nhqk\", [queries, keys]) # (32, 8, 24, 24)\n",
        "        # Dot product each query with each key.\n",
        "        #   - We get a 24*24 (like a covariance matrix) in encoder self attention.\n",
        "        #   - We get a 23*23 (like a covariance matrix) in decoder self attention.\n",
        "        #   - We get a 23*24 (like a covariance matrix) in decoder cross attention.\n",
        "\n",
        "        # This for each head. (8,24,24). On all samples in batch. (32,8,24,24)\n",
        "\n",
        "        # Mask padded indices so their weights become close to 0   # (32, 8, 24, 24)\n",
        "        if mask is not None:\n",
        "\n",
        "            energy = energy.masked_fill(mask == 0, float(\"-1e20\"))\n",
        "\n",
        "\n",
        "        # Normalize energy values similarly to so that they sum to 1. Also divide by scaling factor for better stability\n",
        "        attention = torch.softmax(energy/ (self.head_dim ** (1/2)), dim=3) # (N, heads, query_len, key_len)\n",
        "        # dim = 3 indicating we operate along row across columns i.e.on query for each key\n",
        "\n",
        "        out = torch.einsum(\"nhqk,nvhd->nqhd\",[attention, values]) # multiplies attention scores with values. #(32, 8, 24, 24) @ (32, 24, 8, 64) → (32, 24, 8, 64)\n",
        "        out = self.fc_out(out.reshape(N, query_len, self.heads * self.head_dim )) # (32, 24 (23 in decoder), 512) # Flatten the last dimensions and send it to fc_out -> # (N, query_len, embed_size)\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "\n",
        "class TransformerBlock(nn.Module):\n",
        "    def __init__(self, embed_size, heads, dropout, forward_expansion):\n",
        "        super().__init__()\n",
        "        self.attention = SelfAttention(embed_size, heads)\n",
        "        self.norm1 = nn.LayerNorm(embed_size)\n",
        "        self.norm2 = nn.LayerNorm(embed_size)\n",
        "\n",
        "        self.feed_forward = nn.Sequential(\n",
        "            nn.Linear(embed_size, forward_expansion*embed_size),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(forward_expansion*embed_size, embed_size)\n",
        "        )\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, value, key, query, mask):\n",
        "\n",
        "        \"\"\"attention = self.attention(value, key, query, mask)\n",
        "        x = self.dropout(self.norm1(query + attention)) # Add skip connection, run through normalization and finally dropout\n",
        "        forward = self.feed_forward(x)\n",
        "        out = self.dropout(self.norm2(x + forward))\"\"\"\n",
        "\n",
        "\n",
        "        # Below is the Pre-LN implementation\n",
        "        attention = self.attention(self.norm1(value), self.norm1(key), self.norm1(query), mask) # Apply self-attention\n",
        "        x = query + self.dropout(attention)  # Skip connection with original query and dropout\n",
        "        forward = self.norm2(x)  # Normalize before feedforward\n",
        "        out = x + self.dropout(self.feed_forward(forward))\n",
        "\n",
        "        return out # (32,24 (23 @ Decoder),512)\n",
        "\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        src_vocab_size,  # Total vocabulary size (number of unique words)\n",
        "        embed_size,      # Dimension of each word embedding # 512\n",
        "        num_layers,      # Number of Transformer blocks # 6\n",
        "        heads,           # Number of self-attention heads # 8\n",
        "        device,          # GPU/CPU device\n",
        "        forward_expansion,  # Expansion factor for the feed-forward layer\n",
        "        dropout,         # Dropout rate\n",
        "        max_length,      # Maximum sentence length\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.embed_size = embed_size\n",
        "        self.device = device\n",
        "        self.word_embedding = nn.Embedding(src_vocab_size, embed_size) # Converts tokenized words into dense embeddings. i.e. each word willl be represented as embedding 1D vector -> 2D vector\n",
        "        self.position_embedding = nn.Embedding(max_length, embed_size) # Adds position information (since Transformers have no recurrence).\n",
        "\n",
        "        self.layers = nn.ModuleList(\n",
        "            [\n",
        "                TransformerBlock(\n",
        "                    embed_size,\n",
        "                    heads,\n",
        "                    dropout = dropout,\n",
        "                    forward_expansion=forward_expansion\n",
        "                    )\n",
        "                for _ in range(num_layers)\n",
        "                ])\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x, mask):\n",
        "        N, seq_length = x.shape #(32,24) # Here x is tokenized representations of Our data # Ex: [\"Cat\",\"Loves\",\"Milk\"] -> [2(bos),7,8,9,3(eos),1(pad),1,...]. Assume N = 32 (batch), seq_length = 24 (words)\n",
        "        positions = torch.arange(0, seq_length).expand(N, seq_length).to(self.device) #Adding positions with numbers for batch size (32,24)\n",
        "        out = self.dropout(self.word_embedding(x) + self.position_embedding(positions)) # (32,24,512) + (32,24,512) Making the positions learnable by creating embeddings to them\n",
        "        # word embedding (\"2\") returns a 512 dimensional vector\n",
        "        for layer in self.layers:\n",
        "            out = layer(out, out, out, mask) # value, key, query (32,24,512), mask (32,1,1,24) which are the input for forward in Transformer Encoder self attention Block\n",
        "            # So masking is done only on the columns i.e. last index. Specifically on the padded indexs\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "class DecoderBlock(nn.Module):\n",
        "    def __init__(self, embed_size, heads, dropout, forward_expansion ):\n",
        "        super().__init__()\n",
        "        self.norm = nn.LayerNorm(embed_size)\n",
        "        self.attention = SelfAttention(embed_size, heads) # Masked Self-Attention\n",
        "        self.transformer_block = TransformerBlock(embed_size, heads, dropout = dropout, forward_expansion = forward_expansion) # Cross-Attention + Feedforward\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, value, key, x, src_mask, trg_mask):\n",
        "        #print(\"Here at Decoder Block sending trg_mask\")\n",
        "        attention = self.attention(self.norm(x), self.norm(x), self.norm(x), trg_mask) # Masked Attention -> (Lower Triangular Mask + padded Tokens Mask) = trg_mask\n",
        "        query = x + self.dropout(attention)\n",
        "        out = self.transformer_block(value, key, query, src_mask) # Just padding Tokens Mask like Encoder Mask\n",
        "\n",
        "        \"\"\"# Post LN Implementation\n",
        "        attention = self.attention(x, x, x, trg_mask) #Uses self-attention where query = key = value = x (decoder’s past words).            # Uses trg_mask → Ensures that each word only attends to past words (not future words).\n",
        "        query = self.dropout(self.norm(attention + x))\n",
        "        out = self.transformer_block(value, key, query, src_mask)\"\"\"\n",
        "        return out\n",
        "\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(\n",
        "            self,\n",
        "            trg_vocab_size,  # Target vocabulary size\n",
        "            embed_size,      # Dimension of each word embedding # 8\n",
        "            num_layers,      # Number of Transformer blocks\n",
        "            heads,           # Number of self-attention heads\n",
        "            device,          # GPU/CPU device\n",
        "            forward_expansion,  # Expansion factor for the feed-forward layer\n",
        "            dropout,         # Dropout rate\n",
        "            max_length,      # Maximum sentence length\n",
        "        ):\n",
        "        super().__init__()\n",
        "        self.embed_size = embed_size\n",
        "        self.device = device\n",
        "        self.word_embedding = nn.Embedding(trg_vocab_size, embed_size) # Converts tokenized words into dense embeddings.\n",
        "        self.position_embedding = nn.Embedding(max_length, embed_size) # Adds position information (since Transformers have no recurrence).\n",
        "\n",
        "        self.layers = nn.ModuleList(\n",
        "            [\n",
        "                DecoderBlock(\n",
        "                    embed_size,\n",
        "                    heads,\n",
        "                    dropout = dropout,\n",
        "                    forward_expansion=forward_expansion\n",
        "                    )\n",
        "                for _ in range(num_layers)\n",
        "                ])\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.fc_out = nn.Linear(embed_size, trg_vocab_size) # Projects the decoder output into target vocabulary scores\n",
        "\n",
        "\n",
        "    def forward(self, x, enc_out, src_mask, trg_mask):\n",
        "        N, seq_length = x.shape  # Here x is tokenized representations of Our data # Ex: ['Katze', 'liebt', 'Milch'] -> [2(bos),7,15,18,1(pad),1,...]. Assume N = 32 (batch), seq_length = 23 (words)\n",
        "        positions = torch.arange(0, seq_length).expand(N, seq_length).to(self.device)  #(32,23)\n",
        "        x = self.dropout(self.word_embedding(x) + self.position_embedding(positions)) # (32,23,512) + (32,23,512)\n",
        "        # word embedding (\"2\") returns a 512 dimensional vector\n",
        "        for layer in self.layers:\n",
        "            x = layer(enc_out, enc_out, x, src_mask, trg_mask) # value(32, 23 (24 @ Cross Attention), 512), key(32, 23 (24 @ Cross Attention), 512), query (32, 23, 512), mask (32, 1, 23, 23) which are the input for forward in Transformer Block\n",
        "\n",
        "        out = self.fc_out(x) # (32, 23, 512) -> (32,23,trg_vocab_size) logit vectors, where each logit corresponds to the probability of a word in the target vocabulary.\n",
        "        return out\n",
        "\n",
        "class Transformer(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        src_vocab_size,\n",
        "        trg_vocab_size,\n",
        "        src_pad_idx,\n",
        "        trg_pad_idx,\n",
        "        embed_size=512,\n",
        "        num_layers=6,\n",
        "        forward_expansion=4,\n",
        "        heads=8,\n",
        "        dropout=0.0,\n",
        "        device=\"cpu\",\n",
        "        max_length=100,\n",
        "    ):\n",
        "\n",
        "        super().__init__()\n",
        "\n",
        "        self.encoder = Encoder(\n",
        "            src_vocab_size,\n",
        "            embed_size,\n",
        "            num_layers,\n",
        "            heads,\n",
        "            device,\n",
        "            forward_expansion,\n",
        "            dropout,\n",
        "            max_length,\n",
        "        )\n",
        "\n",
        "        self.decoder = Decoder(\n",
        "            trg_vocab_size,\n",
        "            embed_size,\n",
        "            num_layers,\n",
        "            heads,\n",
        "            device,\n",
        "            forward_expansion,\n",
        "            dropout,\n",
        "            max_length,\n",
        "        )\n",
        "\n",
        "        self.src_pad_idx = src_pad_idx\n",
        "        self.trg_pad_idx = trg_pad_idx\n",
        "        self.device = device\n",
        "        for p in self.parameters():\n",
        "            if p.dim() > 1:\n",
        "                nn.init.xavier_uniform_(p)\n",
        "\n",
        "\n",
        "    def make_src_mask(self, src):\n",
        "        src_mask = (src != self.src_pad_idx).unsqueeze(1).unsqueeze(2)\n",
        "\n",
        "        # (N = src.shape[0], 1, 1, src.shape[1])\n",
        "\n",
        "        #tensor([[[[ True,  True,  True,  ..., True,  True,  True,  True]]],   The Cat was trying to.....in the house <eos>\n",
        "        #                                 .\n",
        "        #                                 .\n",
        "        #                                 .\n",
        "        #[[[ True,  True, True, False, False, False, False]]]])         Cats Love Milk <eos> <pad>......<pad> <pad>\n",
        "\n",
        "        return src_mask.to(self.device)\n",
        "\n",
        "\n",
        "    def make_trg_mask(self, trg):\n",
        "        N, trg_len = trg.shape\n",
        "        # 1. Causal (Look-Ahead) Mask (lower triangular, prevents attending to future tokens)\n",
        "        causal_mask = torch.tril(torch.ones((trg_len, trg_len), device=self.device)).bool() # Shape: (trg_len, trg_len) e.g., (23, 23)\n",
        "\n",
        "        # 2. Target Padding Mask (prevents attending to <pad> tokens in the target sequence itself) This is similar to src_mask, but for the target sequence.\n",
        "        padding_mask = (trg != self.trg_pad_idx).unsqueeze(1).unsqueeze(2).bool()# Shape: (N, 1, 1, trg_len) e.g., (32, 1, 1, 23)\n",
        "\n",
        "        # 3. Combine them using logical AND (position is True only if BOTH are True)\n",
        "        combined_mask = causal_mask.unsqueeze(0).unsqueeze(0) & padding_mask # (32, 1, 23, 23)\n",
        "        return combined_mask.to(self.device)\n",
        "\n",
        "\n",
        "    def forward(self, src, trg):\n",
        "        src_mask = self.make_src_mask(src) #(32,1,1,24) Booleans # To not consider any padding values\n",
        "        trg_mask = self.make_trg_mask(trg) # (32,1,23,23)  Ones and Zeros # Lower Triangualr matrix to not allow peeking and not attending to padded tokens\n",
        "        enc_src = self.encoder(src, src_mask)\n",
        "        out = self.decoder(trg, enc_src, src_mask, trg_mask)\n",
        "        return out\n"
      ],
      "metadata": {
        "id": "jc-Bj1SEN30t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to yield tokens (for vocab building) sepearate for each vocabulary\n",
        "def yield_tokens(data, tokenizer, lang=\"en\"):\n",
        "    for src_text, tgt_text in data:\n",
        "        text = src_text if lang == \"en\" else tgt_text  # Choose English or German text\n",
        "        yield tokenizer(text)\n",
        "\n",
        "# converts into a tensor of numerical token IDs -> [2,21,45,.....,3]\n",
        "def text_to_tensor(text, vocab, tokenizer):\n",
        "    tokens = [vocab[\"<bos>\"]] + [vocab[token] if token in vocab else vocab[\"<unk>\"] for token in tokenizer(text)] + [vocab[\"<eos>\"]]\n",
        "    return torch.tensor(tokens, dtype=torch.long)\n",
        "\n",
        "\n",
        "def collate_fn(batch):\n",
        "    src_batch, tgt_batch = [], []\n",
        "    for src_text, tgt_text in batch:\n",
        "        src_batch.append(text_to_tensor(src_text, en_vocab, en_tokenizer))\n",
        "        tgt_batch.append(text_to_tensor(tgt_text, de_vocab, de_tokenizer))\n",
        "\n",
        "    # --- REVISED PADDING ---\n",
        "    # Find max length for source batch\n",
        "    max_len_src = max(len(seq) for seq in src_batch)\n",
        "    # Find max length for target batch\n",
        "    max_len_tgt = max(len(seq) for seq in tgt_batch)\n",
        "\n",
        "    # Pad source sequences to max_len_src\n",
        "    src_batch_padded = [\n",
        "        torch.cat([seq, torch.full((max_len_src - len(seq),), en_vocab[\"<pad>\"], dtype=torch.long)])\n",
        "        for seq in src_batch\n",
        "    ]\n",
        "    # Pad target sequences to max_len_tgt\n",
        "    tgt_batch_padded = [\n",
        "        torch.cat([seq, torch.full((max_len_tgt - len(seq),), de_vocab[\"<pad>\"], dtype=torch.long)])\n",
        "        for seq in tgt_batch\n",
        "    ]\n",
        "\n",
        "    src_batch_stacked = torch.stack(src_batch_padded)\n",
        "    tgt_batch_stacked = torch.stack(tgt_batch_padded)\n",
        "\n",
        "    return src_batch_stacked, tgt_batch_stacked"
      ],
      "metadata": {
        "id": "bdrJqVeo7cEx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenizers\n",
        "# Tokenizer converts text into a list of tokens (words)\n",
        "en_tokenizer = get_tokenizer(\"spacy\", language = \"en_core_web_sm\") # Small English tokenizer model\n",
        "de_tokenizer = get_tokenizer(\"spacy\", language = \"de_core_news_sm\") # Small German tokenizer model\n",
        "\n",
        "# Example:\n",
        "sample_text = \"This is an example sentence.\"\n",
        "print(\"Tokenized sample:\", en_tokenizer(sample_text))\n",
        "# Expected Output: ['This', 'is', 'an', 'example', 'sentence', '.']\n",
        "\n",
        "# Loading the data\n",
        "full_train_data = list(Multi30k(split = 'train', language_pair = ('en', 'de')))[:1000] # Multi30K is a dataset for English-German translation.\n",
        "# Shuffle the data to ensure randomness\n",
        "random.shuffle(full_train_data)\n",
        "\n",
        "# Split dataset into train, validation, and test (80-10-10 split)\n",
        "train_size = int(0.8 * len(full_train_data))  # 80% for training\n",
        "val_size = int(0.1 * len(full_train_data))    # 10% for validation\n",
        "test_size = len(full_train_data) - train_size - val_size  # Remaining 10% for testing\n",
        "\n",
        "# Create subsets\n",
        "train_data = full_train_data[:train_size]\n",
        "val_data = full_train_data[train_size:train_size + val_size]\n",
        "test_data = full_train_data[train_size + val_size:]\n",
        "\n",
        "print(f\"Train Data: {len(train_data)} samples\")\n",
        "print(f\"Validation Data: {len(val_data)} samples\")\n",
        "print(f\"Test Data: {len(test_data)} samples\")\n",
        "\n",
        "\n",
        "print(\"Loaded first 2 samples:\", train_data[:2])  # Print first two samples\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hod_zJw_PoyZ",
        "outputId": "b29d96e4-ddd2-4adb-ca27-7a839de67749"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokenized sample: ['This', 'is', 'an', 'example', 'sentence', '.']\n",
            "Train Data: 800 samples\n",
            "Validation Data: 100 samples\n",
            "Test Data: 100 samples\n",
            "Loaded first 2 samples: [('Three boys play with paddles on the beach.', 'Drei Jungen spielen am Strand mit Paddeln.'), ('A marketplace with rolling carts selling fruits.', 'Ein Marktplatz mit fahrbaren Wagen, wo Obst verkauft wird.')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NGBii_2dRNgp",
        "outputId": "7c589023-887d-4321-c95d-3630c50adabb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 1\n",
        "clip = 5 # Gradient Clipping to prevent exploding gradients\n",
        "embed_size = 512\n",
        "num_layers=6\n",
        "forward_expansion=4\n",
        "heads=8\n",
        "dropout=0.05\n",
        "device=device\n",
        "max_length=256\n",
        "batch_size = 128"
      ],
      "metadata": {
        "id": "KAd76Z1BY2V6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Build vocab for the data i.e. all unique tokens(text) to Uniques IDs from the data\n",
        "en_vocab = build_vocab_from_iterator(yield_tokens(train_data, en_tokenizer, lang = \"en\"), specials=[\"<unk>\", \"<pad>\", \"<bos>\", \"<eos>\"])\n",
        "de_vocab = build_vocab_from_iterator(yield_tokens(train_data, de_tokenizer, lang = \"de\"), specials=[\"<unk>\", \"<pad>\", \"<bos>\", \"<eos>\"])\n",
        "\n",
        "# Set unknown token index (handles words not in vocab)\n",
        "en_vocab.set_default_index(en_vocab[\"<unk>\"])\n",
        "de_vocab.set_default_index(de_vocab[\"<unk>\"])\n",
        "\n",
        "print(f\"Length of English vocab is {len(en_vocab)} and German vocab is {len(de_vocab)} for {len(train_data)} samples\")\n",
        "\n",
        "# DataLoader handles **shuffling**, **batching**, and **efficient loading**.\n",
        "train_dataloader = DataLoader(train_data, batch_size = batch_size, collate_fn = collate_fn)\n",
        "val_dataloader = DataLoader(val_data, batch_size = batch_size, collate_fn = collate_fn)\n",
        "\n",
        "\n",
        "for src_batch, tgt_batch in train_dataloader:\n",
        "    print(f\"First Source batch shape : {src_batch.shape} ; First Target Batch shape : {tgt_batch.shape}\")\n",
        "    break\n",
        "\n",
        "\n",
        "sample_german_sentence = train_data[0][1]  # Get first German sentence\n",
        "print(\"German sentence:\", sample_german_sentence)\n",
        "print(\"Tokenized:\", de_tokenizer(sample_german_sentence))\n",
        "tokens = de_tokenizer(\"Zwei junge weiße Männer sind im Freien .\")\n",
        "print(\"Token IDs:\", [de_vocab[token] for token in tokens])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F5DXx3sARDHl",
        "outputId": "150afa55-df29-43c3-d735-527503a481c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Length of English vocab is 1686 and German vocab is 1928 for 800 samples\n",
            "First Source batch shape : torch.Size([128, 27]) ; First Target Batch shape : torch.Size([128, 30])\n",
            "German sentence: Drei Jungen spielen am Strand mit Paddeln.\n",
            "Tokenized: ['Drei', 'Jungen', 'spielen', 'am', 'Strand', 'mit', 'Paddeln', '.']\n",
            "Token IDs: [22, 83, 681, 36, 105, 21, 51, 4]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, dataloader, optimizer, scheduler, loss_fn, device):\n",
        "    model.train() # Setting the model to train mode\n",
        "    epoch_loss = 0\n",
        "\n",
        "    # dataloader = [(32,24), #English\n",
        "    #                (32,24) #German]\n",
        "    for batch_idx, (src,tgt) in enumerate(dataloader):\n",
        "        src, tgt = src.to(device), tgt.to(device)\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Target input (remove last token) and target output (remove first token) # Teacher forcing strategy for seq-to-seq models\n",
        "        tgt_input = tgt[:,:-1] # Input to decoder # (32,23)\n",
        "        tgt_output = tgt[:,1:] # Target decoder output # (32,23)\n",
        "\n",
        "        # Forward pass\n",
        "        output = model(src, tgt_input) # (32, 23, 17000) -> (Batch_Size, Max_Target_Seq_Len - 1, Target_Vocab_Size)\n",
        "\n",
        "\n",
        "        # Reshape output to match loss function expectations\n",
        "        output = output.reshape(-1, output.shape[-1])  # (736, 17000)-> [batch*seq_len, vocab_size]\n",
        "        tgt_output = tgt_output.reshape(-1) # (736,) -> [batch*seq_len]\n",
        "\n",
        "        # Compute loss\n",
        "        loss = loss_fn(output, tgt_output)\n",
        "        loss.backward()\n",
        "\n",
        "        # Gradient Clipping to ptevent exploding gradients\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=clip)\n",
        "\n",
        "        # Update weights\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "\n",
        "        epoch_loss += loss.item()\n",
        "\n",
        "        # # Print loss every 100 batches\n",
        "        # if batch_idx % 100 == 0:\n",
        "        #     print(f\"Batch [{batch_idx}/{len(train_dataloader)}], Loss: {loss.item():.4f}\")\n",
        "\n",
        "    return epoch_loss / len(dataloader)\n",
        "\n",
        "\n",
        "\n",
        "def evaluate(model, dataloader, loss_fn, device):\n",
        "    model.eval()  # Set model to evaluation mode\n",
        "    epoch_loss = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for src, tgt in dataloader:\n",
        "            src, tgt = src.to(device), tgt.to(device)\n",
        "\n",
        "\n",
        "            tgt_input = tgt[:, :-1]  # Input to decoder (without <eos>)\n",
        "            tgt_output = tgt[:, 1:]  # Target output (without <bos>)\n",
        "\n",
        "\n",
        "            output = model(src, tgt_input)\n",
        "\n",
        "            # Reshape output for loss computation\n",
        "            output = output.reshape(-1, output.shape[-1])\n",
        "            tgt_output = tgt_output.reshape(-1)\n",
        "\n",
        "            loss = loss_fn(output, tgt_output)\n",
        "            epoch_loss += loss.item()\n",
        "\n",
        "    return epoch_loss / len(dataloader)\n"
      ],
      "metadata": {
        "id": "4G5NJDi3Sx2t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "src_pad_idx = en_vocab[\"<pad>\"]\n",
        "trg_pad_idx = de_vocab[\"<pad>\"]\n",
        "src_vocab_size = len(en_vocab)\n",
        "trg_vocab_size = len(de_vocab)\n",
        "\n",
        "# Define Transformer model\n",
        "model = Transformer(\n",
        "    src_vocab_size,\n",
        "    trg_vocab_size,\n",
        "    src_pad_idx,\n",
        "    trg_pad_idx,\n",
        "    embed_size=embed_size,\n",
        "    num_layers=num_layers,\n",
        "    forward_expansion=forward_expansion,\n",
        "    heads=heads,\n",
        "    dropout=dropout,\n",
        "    device=device,\n",
        "    max_length=max_length,\n",
        ").to(device)\n",
        "\n",
        "loss_fn = torch.nn.CrossEntropyLoss(ignore_index=trg_pad_idx, label_smoothing=0.1)\n",
        "\n",
        "optimizer = optim.Adam(\n",
        "    model.parameters(),\n",
        "    lr=0.001,            # Initial learning rate\n",
        "    betas=(0.9, 0.98),   # β1 = 0.9, β2 = 0.98\n",
        "    eps=1e-9             # Small epsilon value for numerical stability\n",
        ")\n",
        "\n",
        "import math\n",
        "\n",
        "class InverseSqrtLR(optim.lr_scheduler.LambdaLR):\n",
        "    def __init__(self, optimizer, d_model, warmup_steps):\n",
        "        self.d_model = d_model\n",
        "        self.warmup_steps = warmup_steps\n",
        "        super().__init__(optimizer, self.lr_lambda)\n",
        "\n",
        "    def lr_lambda(self, step_num):\n",
        "        step_num = max(step_num, 1)  # Ensure step_num is at least 1\n",
        "        return (self.d_model ** -0.5) * min(step_num ** -0.5, step_num * (self.warmup_steps ** -1.5))\n",
        "\n",
        "# Set up the scheduler with warm-up steps\n",
        "warmup_steps = 4000\n",
        "scheduler = InverseSqrtLR(optimizer, d_model=512, warmup_steps=warmup_steps)"
      ],
      "metadata": {
        "id": "BY301Ze2Rrzp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the directory path\n",
        "import os\n",
        "import datetime\n",
        "\n",
        "model_dir = \"/content/drive/My Drive/Colab Notebooks/models\"\n",
        "# Create the directory if it doesn't exist\n",
        "os.makedirs(model_dir, exist_ok=True)\n",
        "timestamp = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "model_filename = f\"best_transformer_model_{timestamp}.pth\"\n",
        "model_path = os.path.join(model_dir, model_filename)\n",
        "\n",
        "\n",
        "# Run training & evaluation\n",
        "best_valid_loss = float(\"inf\")\n",
        "# Store loss values for visualization\n",
        "train_losses = []\n",
        "valid_losses = []\n",
        "\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    start_time = time.time()\n",
        "\n",
        "    train_loss = train(model, train_dataloader, optimizer, scheduler, loss_fn, device)\n",
        "    valid_loss = evaluate(model, val_dataloader, loss_fn, device)\n",
        "\n",
        "\n",
        "    end_time = time.time()\n",
        "    epoch_mins, epoch_secs = divmod(int(end_time - start_time), 60)\n",
        "\n",
        "    print(f\"Epoch {epoch+1}: Train Loss: {train_loss:.3f} | Validation Loss: {valid_loss:.3f} Time: {epoch_mins}m {epoch_secs}s\")\n",
        "\n",
        "    train_losses.append(train_loss)\n",
        "    valid_losses.append(valid_loss)\n",
        "\n",
        "    # # Save the model if validation loss improves\n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), model_path)\n",
        "        print(\"Model saved to {model_path}!\")\n",
        "\n",
        "# --- End of Training ---\n",
        "plt.ioff() # Turn off interactive mode\n",
        "plt.show() # Keep the final plot displayed after training finishes\n",
        "\n",
        "# Plot Training & Validation Loss After Training\n",
        "plt.figure(figsize=(8, 5))\n",
        "plt.plot(range(1, num_epochs+1), train_losses, label='Training Loss')\n",
        "plt.plot(range(1, num_epochs+1), valid_losses, label='Validation Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Training & Validation Loss Over Epochs')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 977
        },
        "id": "aJjDRsOeS_Bf",
        "outputId": "89f902f9-e966-49af-cf2d-4f404118c371"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: Train Loss: 221.083 | Validation Loss: 214.033 Time: 2m 38s\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to {model_path}!\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NEdSQeTAYyRt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "s3jio4WQYyPI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Uew4hY-CYyMy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "N7AaPMlVYyKM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IXiBvbsdYyEd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_model(en_vocab, de_vocab, embed_size, num_layers, forward_expansion, heads, dropout, device, max_length, model_path):\n",
        "    print(\"Loading model...\")\n",
        "\n",
        "\n",
        "    checkpoint = torch.load(model_path, map_location=device)\n",
        "\n",
        "    model = Transformer(len(en_vocab), len(de_vocab), en_vocab[\"<pad>\"], de_vocab[\"<pad>\"],\n",
        "                        embed_size=embed_size,\n",
        "                        num_layers=num_layers,\n",
        "                        forward_expansion=forward_expansion,\n",
        "                        heads=heads,\n",
        "                        dropout=dropout,\n",
        "                        device=device,\n",
        "                        max_length=max_length).to(device)\n",
        "\n",
        "        # Get the model's current embedding weights\n",
        "    model_state_dict = model.state_dict()\n",
        "\n",
        "    # Resize encoder embedding if vocab size changed\n",
        "    if checkpoint[\"encoder.word_embedding.weight\"].shape != model_state_dict[\"encoder.word_embedding.weight\"].shape:\n",
        "        print(\"Resizing Encoder Embedding Layer...\")\n",
        "        old_embedding = checkpoint[\"encoder.word_embedding.weight\"]\n",
        "        new_embedding = model_state_dict[\"encoder.word_embedding.weight\"]\n",
        "        min_size = min(old_embedding.shape[0], new_embedding.shape[0])\n",
        "        new_embedding[:min_size, :] = old_embedding[:min_size, :]\n",
        "        checkpoint[\"encoder.word_embedding.weight\"] = new_embedding\n",
        "\n",
        "    # Resize decoder embedding if vocab size changed\n",
        "    if checkpoint[\"decoder.word_embedding.weight\"].shape != model_state_dict[\"decoder.word_embedding.weight\"].shape:\n",
        "        print(\"Resizing Decoder Embedding Layer...\")\n",
        "        old_embedding = checkpoint[\"decoder.word_embedding.weight\"]\n",
        "        new_embedding = model_state_dict[\"decoder.word_embedding.weight\"]\n",
        "        min_size = min(old_embedding.shape[0], new_embedding.shape[0])\n",
        "        new_embedding[:min_size, :] = old_embedding[:min_size, :]\n",
        "        checkpoint[\"decoder.word_embedding.weight\"] = new_embedding\n",
        "\n",
        "    # Resize output layer if vocab size changed\n",
        "    if checkpoint[\"decoder.fc_out.weight\"].shape != model_state_dict[\"decoder.fc_out.weight\"].shape:\n",
        "        print(\"Resizing Decoder Output Layer...\")\n",
        "        old_output = checkpoint[\"decoder.fc_out.weight\"]\n",
        "        new_output = model_state_dict[\"decoder.fc_out.weight\"]\n",
        "        min_size = min(old_output.shape[0], new_output.shape[0])\n",
        "        new_output[:min_size, :] = old_output[:min_size, :]\n",
        "        checkpoint[\"decoder.fc_out.weight\"] = new_output\n",
        "\n",
        "    # Resize output bias if vocab size changed\n",
        "    if checkpoint[\"decoder.fc_out.bias\"].shape != model_state_dict[\"decoder.fc_out.bias\"].shape:\n",
        "        print(\"Resizing Decoder Output Bias...\")\n",
        "        old_bias = checkpoint[\"decoder.fc_out.bias\"]\n",
        "        new_bias = model_state_dict[\"decoder.fc_out.bias\"]\n",
        "        min_size = min(old_bias.shape[0], new_bias.shape[0])\n",
        "        new_bias[:min_size] = old_bias[:min_size]\n",
        "        checkpoint[\"decoder.fc_out.bias\"] = new_bias\n",
        "\n",
        "    # Load the adjusted weights (ignore strict mismatches)\n",
        "    model.load_state_dict(checkpoint, strict=False)\n",
        "    model.to(device)\n",
        "\n",
        "    return model\n",
        "\n",
        "def translate_sentence(model, sentence, src_vocab, trg_vocab, tokenizer, device, max_length=50):\n",
        "    model.eval()  # Set model to evaluation mode\n",
        "\n",
        "    # Tokenize and convert to tensor safely\n",
        "    tokens = [src_vocab[\"<bos>\"]] + [\n",
        "        src_vocab[token] if token in src_vocab else src_vocab[\"<unk>\"] for token in tokenizer(sentence)\n",
        "    ] + [src_vocab[\"<eos>\"]]\n",
        "\n",
        "    # Debugging: Check if any tokens are out of vocab\n",
        "    for token in tokenizer(sentence):\n",
        "        if token not in src_vocab:\n",
        "            print(f\"WARNING: Token '{token}' not in vocab. Mapping to <unk>.\")\n",
        "\n",
        "    # Convert tokens to tensor and add batch dimension\n",
        "    sentence_tensor = torch.tensor(tokens, dtype=torch.long).unsqueeze(0).to(device)\n",
        "\n",
        "    print(f\"\\n Tokenized Sentence: {tokens} Sentence Tensor Shape: {sentence_tensor.shape}\")\n",
        "    # print(f\" Max Index in Sentence: {max(tokens)}, Vocab Size: {len(src_vocab)}\")\n",
        "\n",
        "    with torch.no_grad():\n",
        "        # Encode the source sentence\n",
        "        src_mask = model.make_src_mask(sentence_tensor)\n",
        "        enc_src = model.encoder(sentence_tensor, src_mask)\n",
        "\n",
        "        # Initialize target sequence with <bos>\n",
        "        trg_indexes = [trg_vocab[\"<bos>\"]]\n",
        "\n",
        "        for i in range(max_length):\n",
        "            trg_tensor = torch.tensor(trg_indexes, dtype=torch.long).unsqueeze(0).to(device)\n",
        "            trg_mask = model.make_trg_mask(trg_tensor)\n",
        "\n",
        "            # Pass through the decoder\n",
        "            output = model.decoder(trg_tensor, enc_src, src_mask, trg_mask)\n",
        "\n",
        "            # Get the next token (greedy decoding)\n",
        "            next_word = output.argmax(2)[:, -1].item()\n",
        "            trg_indexes.append(next_word)\n",
        "\n",
        "            # Debugging: Print top predictions\n",
        "            probs = torch.softmax(output[:, -1, :], dim=-1)\n",
        "            top5 = torch.topk(probs, 5)\n",
        "            # print(f\"Step {i+1}: Next token: {next_word} ({trg_vocab.get_itos()[next_word]}) | Top5 Predictions: {top5.indices.tolist()}\")\n",
        "            print(f\"Generated Indexes : {trg_indexes} and shape {len(trg_indexes)}\")\n",
        "            # Stop if <eos> is generated\n",
        "            if next_word == trg_vocab[\"<eos>\"] or len(trg_indexes) == sentence_tensor.shape[1]:\n",
        "                print(\" Stopping as <eos> is generated.\")\n",
        "                break\n",
        "\n",
        "    translated_tokens = [trg_vocab.get_itos()[idx] for idx in trg_indexes]\n",
        "    print(f\" Translated Tokens: {translated_tokens[1:-1]}\")  # Excluding <bos> and <eos>\n",
        "    return translated_tokens[1:-1]  # Remove <bos> and <eos>\n"
      ],
      "metadata": {
        "id": "VZSsecjNYx61"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_path = os.path.join(model_dir, \"best_transformer_model.pth\")\n",
        "model = load_model(en_vocab, de_vocab, embed_size, num_layers, forward_expansion, heads, dropout, device, max_length, model_path)\n",
        "\n",
        "\n",
        "\n",
        "# Example test sentence\n",
        "test_sentence = \"A man is playing a guitar\"\n",
        "\n",
        "translated_output = translate_sentence(model, test_sentence, en_vocab, de_vocab, en_tokenizer, device)\n",
        "print(\"Translated Sentence:\", \" \".join(translated_output))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rwx-vPd9OC2d",
        "outputId": "91d531fd-a88b-4cb3-f0a0-8829e14b2941"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading model...\n",
            "Resizing Encoder Embedding Layer...\n",
            "Resizing Decoder Embedding Layer...\n",
            "Resizing Decoder Output Layer...\n",
            "Resizing Decoder Output Bias...\n",
            "\n",
            " Tokenized Sentence: [2, 6, 10, 11, 33, 4, 113, 3] Sentence Tensor Shape: torch.Size([1, 8])\n",
            "Generated Indexes : [2, 70] and shape 2\n",
            "Generated Indexes : [2, 70, 70] and shape 3\n",
            "Generated Indexes : [2, 70, 70, 134] and shape 4\n",
            "Generated Indexes : [2, 70, 70, 134, 134] and shape 5\n",
            "Generated Indexes : [2, 70, 70, 134, 134, 134] and shape 6\n",
            "Generated Indexes : [2, 70, 70, 134, 134, 134, 64] and shape 7\n",
            "Generated Indexes : [2, 70, 70, 134, 134, 134, 64, 64] and shape 8\n",
            " Stopping as <eos> is generated.\n",
            " Translated Tokens: ['blauen', 'blauen', 'liegt', 'liegt', 'liegt', 'spielen']\n",
            "Translated Sentence: blauen blauen liegt liegt liegt spielen\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_bleu(model, test_data, src_vocab, trg_vocab, src_tokenizer, trg_tokenizer, device):\n",
        "    model.eval()\n",
        "    references = []\n",
        "    hypotheses = []\n",
        "\n",
        "    for src_sentence, trg_sentence in test_data:\n",
        "        reference = [trg_tokenizer(trg_sentence)]  # Tokenize the ground-truth sentence\n",
        "        hypothesis = translate_sentence(model, src_sentence, src_vocab, trg_vocab, src_tokenizer, device)\n",
        "\n",
        "        references.append(reference)\n",
        "        hypotheses.append(hypothesis)\n",
        "\n",
        "    score = bleu_score(hypotheses, references)\n",
        "    return score\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Compute BLEU Score\n",
        "bleu = compute_bleu(model, test_data[:2], en_vocab, de_vocab, en_tokenizer, de_tokenizer, device)\n",
        "print(f\"BLEU Score: {bleu:.4f}\")\n"
      ],
      "metadata": {
        "id": "QSgz4GzdZ9sS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IbJypXAo9_A-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YSyIGu2m9_DO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "P-tapSTD9_FU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7M-U__6J9_Hf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Ig6FaPzC9_Jp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "89iR1zGn9_LU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6btgt71n9_Oc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "db4b5Na49_RC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}