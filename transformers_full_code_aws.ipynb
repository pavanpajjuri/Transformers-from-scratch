{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "YoBq61T_OPqf",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: torch 2.2.2\n",
      "Uninstalling torch-2.2.2:\n",
      "  Successfully uninstalled torch-2.2.2\n",
      "Found existing installation: torchtext 0.17.2\n",
      "Uninstalling torchtext-0.17.2:\n",
      "  Successfully uninstalled torchtext-0.17.2\n",
      "Found existing installation: torchaudio 2.2.2\n",
      "Uninstalling torchaudio-2.2.2:\n",
      "  Successfully uninstalled torchaudio-2.2.2\n",
      "Found existing installation: torchvision 0.17.2\n",
      "Uninstalling torchvision-0.17.2:\n",
      "  Successfully uninstalled torchvision-0.17.2\n",
      "\u001b[33mWARNING: Skipping spacy as it is not installed.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Skipping thinc as it is not installed.\u001b[0m\u001b[33m\n",
      "\u001b[0mFound existing installation: numpy 1.26.4\n",
      "Uninstalling numpy-1.26.4:\n",
      "  Successfully uninstalled numpy-1.26.4\n",
      "Found existing installation: sagemaker 2.247.0\n",
      "Uninstalling sagemaker-2.247.0:\n",
      "  Successfully uninstalled sagemaker-2.247.0\n",
      "\u001b[33mWARNING: Skipping transformers as it is not installed.\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting torch==2.1.0\n",
      "  Downloading torch-2.1.0-cp310-cp310-manylinux1_x86_64.whl.metadata (25 kB)\n",
      "Collecting torchtext==0.16.0\n",
      "  Downloading torchtext-0.16.0-cp310-cp310-manylinux1_x86_64.whl.metadata (7.5 kB)\n",
      "Collecting filelock (from torch==2.1.0)\n",
      "  Downloading filelock-3.18.0-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting typing-extensions (from torch==2.1.0)\n",
      "  Downloading typing_extensions-4.14.1-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting sympy (from torch==2.1.0)\n",
      "  Downloading sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting networkx (from torch==2.1.0)\n",
      "  Downloading networkx-3.4.2-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting jinja2 (from torch==2.1.0)\n",
      "  Downloading jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting fsspec (from torch==2.1.0)\n",
      "  Downloading fsspec-2025.7.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch==2.1.0)\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch==2.1.0)\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch==2.1.0)\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch==2.1.0)\n",
      "  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch==2.1.0)\n",
      "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch==2.1.0)\n",
      "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.2.106 (from torch==2.1.0)\n",
      "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch==2.1.0)\n",
      "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch==2.1.0)\n",
      "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-nccl-cu12==2.18.1 (from torch==2.1.0)\n",
      "  Downloading nvidia_nccl_cu12-2.18.1-py3-none-manylinux1_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-nvtx-cu12==12.1.105 (from torch==2.1.0)\n",
      "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting triton==2.1.0 (from torch==2.1.0)\n",
      "  Downloading triton-2.1.0-0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.3 kB)\n",
      "Collecting tqdm (from torchtext==0.16.0)\n",
      "  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting requests (from torchtext==0.16.0)\n",
      "  Downloading requests-2.32.4-py3-none-any.whl.metadata (4.9 kB)\n",
      "Collecting numpy (from torchtext==0.16.0)\n",
      "  Downloading numpy-2.2.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (62 kB)\n",
      "Collecting torchdata==0.7.0 (from torchtext==0.16.0)\n",
      "  Downloading torchdata-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n",
      "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch==2.1.0)\n",
      "  Downloading nvidia_nvjitlink_cu12-12.9.86-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting urllib3>=1.25 (from torchdata==0.7.0->torchtext==0.16.0)\n",
      "  Downloading urllib3-2.5.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting MarkupSafe>=2.0 (from jinja2->torch==2.1.0)\n",
      "  Downloading MarkupSafe-3.0.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.0 kB)\n",
      "Collecting charset_normalizer<4,>=2 (from requests->torchtext==0.16.0)\n",
      "  Downloading charset_normalizer-3.4.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (35 kB)\n",
      "Collecting idna<4,>=2.5 (from requests->torchtext==0.16.0)\n",
      "  Downloading idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting certifi>=2017.4.17 (from requests->torchtext==0.16.0)\n",
      "  Downloading certifi-2025.7.14-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy->torch==2.1.0)\n",
      "  Downloading mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Downloading torch-2.1.0-cp310-cp310-manylinux1_x86_64.whl (670.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m670.2/670.2 MB\u001b[0m \u001b[31m204.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading torchtext-0.16.0-cp310-cp310-manylinux1_x86_64.whl (2.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m312.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m261.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m213.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m214.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m677.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m251.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m231.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m249.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m232.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m256.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nccl_cu12-2.18.1-py3-none-manylinux1_x86_64.whl (209.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.8/209.8 MB\u001b[0m \u001b[31m221.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
      "Downloading torchdata-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.7/4.7 MB\u001b[0m \u001b[31m179.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading triton-2.1.0-0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.2/89.2 MB\u001b[0m \u001b[31m194.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading urllib3-2.5.0-py3-none-any.whl (129 kB)\n",
      "Downloading filelock-3.18.0-py3-none-any.whl (16 kB)\n",
      "Downloading fsspec-2025.7.0-py3-none-any.whl (199 kB)\n",
      "Downloading jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
      "Downloading MarkupSafe-3.0.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (20 kB)\n",
      "Downloading networkx-3.4.2-py3-none-any.whl (1.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m594.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading numpy-2.2.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.8/16.8 MB\u001b[0m \u001b[31m371.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.9.86-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (39.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39.7/39.7 MB\u001b[0m \u001b[31m352.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading requests-2.32.4-py3-none-any.whl (64 kB)\n",
      "Downloading charset_normalizer-3.4.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (149 kB)\n",
      "Downloading idna-3.10-py3-none-any.whl (70 kB)\n",
      "Downloading certifi-2025.7.14-py3-none-any.whl (162 kB)\n",
      "Downloading sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m374.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.2/536.2 kB\u001b[0m \u001b[31m644.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Downloading typing_extensions-4.14.1-py3-none-any.whl (43 kB)\n",
      "Installing collected packages: mpmath, urllib3, typing-extensions, tqdm, sympy, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, numpy, networkx, MarkupSafe, idna, fsspec, filelock, charset_normalizer, certifi, triton, requests, nvidia-cusparse-cu12, nvidia-cudnn-cu12, jinja2, nvidia-cusolver-cu12, torch, torchdata, torchtext\n",
      "\u001b[2K  Attempting uninstall: mpmath\n",
      "\u001b[2K    Found existing installation: mpmath 1.3.0\n",
      "\u001b[2K    Uninstalling mpmath-1.3.0:\n",
      "\u001b[2K      Successfully uninstalled mpmath-1.3.0\n",
      "\u001b[2K  Attempting uninstall: urllib3━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 0/31\u001b[0m [mpmath]\n",
      "\u001b[2K    Found existing installation: urllib3 1.26.19 \u001b[32m 0/31\u001b[0m [mpmath]\n",
      "\u001b[2K    Uninstalling urllib3-1.26.19:━━━━━━━━━━━\u001b[0m \u001b[32m 0/31\u001b[0m [mpmath]\n",
      "\u001b[2K      Successfully uninstalled urllib3-1.26.190m \u001b[32m 0/31\u001b[0m [mpmath]\n",
      "\u001b[2K  Attempting uninstall: typing-extensions━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 1/31\u001b[0m [urllib3]\n",
      "\u001b[2K    Found existing installation: typing_extensions 4.14.0━━━━━\u001b[0m \u001b[32m 1/31\u001b[0m [urllib3]\n",
      "\u001b[2K    Uninstalling typing_extensions-4.14.0:━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 1/31\u001b[0m [urllib3]\n",
      "\u001b[2K      Successfully uninstalled typing_extensions-4.14.0━━━━━━━━━━━\u001b[0m \u001b[32m 2/31\u001b[0m [typing-extensions]\n",
      "\u001b[2K  Attempting uninstall: tqdm━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 2/31\u001b[0m [typing-extensions]\n",
      "\u001b[2K    Found existing installation: tqdm 4.67.1━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 2/31\u001b[0m [typing-extensions]\n",
      "\u001b[2K    Uninstalling tqdm-4.67.1:━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 2/31\u001b[0m [typing-extensions]\n",
      "\u001b[2K      Successfully uninstalled tqdm-4.67.1━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 2/31\u001b[0m [typing-extensions]\n",
      "\u001b[2K  Attempting uninstall: sympym━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 3/31\u001b[0m [tqdm]tensions]\n",
      "\u001b[2K    Found existing installation: sympy 1.14.0━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 3/31\u001b[0m [tqdm]\n",
      "\u001b[2K    Uninstalling sympy-1.14.0:0m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 4/31\u001b[0m [sympy]\n",
      "\u001b[2K      Successfully uninstalled sympy-1.14.0━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 4/31\u001b[0m [sympy]\n",
      "\u001b[2K  Attempting uninstall: networkx90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14/31\u001b[0m [numpy]-cublas-cu12]u12]\n",
      "\u001b[2K    Found existing installation: networkx 3.4.2━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14/31\u001b[0m [numpy]\n",
      "\u001b[2K    Uninstalling networkx-3.4.2:[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15/31\u001b[0m [networkx]\n",
      "\u001b[2K      Successfully uninstalled networkx-3.4.2━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15/31\u001b[0m [networkx]\n",
      "\u001b[2K  Attempting uninstall: MarkupSafe0m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15/31\u001b[0m [networkx]\n",
      "\u001b[2K    Found existing installation: MarkupSafe 3.0.2━━━━━━━━━━━━━\u001b[0m \u001b[32m15/31\u001b[0m [networkx]\n",
      "\u001b[2K    Uninstalling MarkupSafe-3.0.2:[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15/31\u001b[0m [networkx]\n",
      "\u001b[2K      Successfully uninstalled MarkupSafe-3.0.2━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15/31\u001b[0m [networkx]\n",
      "\u001b[2K  Attempting uninstall: idna[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15/31\u001b[0m [networkx]\n",
      "\u001b[2K    Found existing installation: idna 3.10━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15/31\u001b[0m [networkx]\n",
      "\u001b[2K    Uninstalling idna-3.10:\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15/31\u001b[0m [networkx]\n",
      "\u001b[2K      Successfully uninstalled idna-3.100m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15/31\u001b[0m [networkx]\n",
      "\u001b[2K  Attempting uninstall: fsspec[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17/31\u001b[0m [idna]\n",
      "\u001b[2K    Found existing installation: fsspec 2025.5.1━━━━━━━━━━━━━━\u001b[0m \u001b[32m17/31\u001b[0m [idna]\n",
      "\u001b[2K    Uninstalling fsspec-2025.5.1:m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17/31\u001b[0m [idna]\n",
      "\u001b[2K      Successfully uninstalled fsspec-2025.5.1━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17/31\u001b[0m [idna]\n",
      "\u001b[2K  Attempting uninstall: filelock1m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17/31\u001b[0m [idna]\n",
      "\u001b[2K    Found existing installation: filelock 3.16.1━━━━━━━━━━━━━━\u001b[0m \u001b[32m17/31\u001b[0m [idna]\n",
      "\u001b[2K    Uninstalling filelock-3.16.1:m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17/31\u001b[0m [idna]\n",
      "\u001b[2K      Successfully uninstalled filelock-3.16.1━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17/31\u001b[0m [idna]\n",
      "\u001b[2K  Attempting uninstall: charset_normalizer\u001b[0m\u001b[90m━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19/31\u001b[0m [filelock]\n",
      "\u001b[2K    Found existing installation: charset-normalizer 3.4.2━━━━━\u001b[0m \u001b[32m19/31\u001b[0m [filelock]\n",
      "\u001b[2K    Uninstalling charset-normalizer-3.4.2:\u001b[90m━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19/31\u001b[0m [filelock]\n",
      "\u001b[2K      Successfully uninstalled charset-normalizer-3.4.2━━━━━━━\u001b[0m \u001b[32m19/31\u001b[0m [filelock]\n",
      "\u001b[2K  Attempting uninstall: certifim\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19/31\u001b[0m [filelock]\n",
      "\u001b[2K    Found existing installation: certifi 2025.6.15━━━━━━━━━━━━\u001b[0m \u001b[32m19/31\u001b[0m [filelock]\n",
      "\u001b[2K    Uninstalling certifi-2025.6.15:1m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19/31\u001b[0m [filelock]\n",
      "\u001b[2K      Successfully uninstalled certifi-2025.6.15━━━━━━━━━━━━━━\u001b[0m \u001b[32m19/31\u001b[0m [filelock]\n",
      "\u001b[2K  Attempting uninstall: triton0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19/31\u001b[0m [filelock]\n",
      "\u001b[2K    Found existing installation: triton 2.2.00m━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19/31\u001b[0m [filelock]\n",
      "\u001b[2K    Uninstalling triton-2.2.0:0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19/31\u001b[0m [filelock]\n",
      "\u001b[2K      Successfully uninstalled triton-2.2.00m╺\u001b[0m\u001b[90m━━━━━━━━━━━\u001b[0m \u001b[32m22/31\u001b[0m [triton]\n",
      "\u001b[2K  Attempting uninstall: requests━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━\u001b[0m \u001b[32m22/31\u001b[0m [triton]\n",
      "\u001b[2K    Found existing installation: requests 2.32.490m━━━━━━━━━━━\u001b[0m \u001b[32m22/31\u001b[0m [triton]\n",
      "\u001b[2K    Uninstalling requests-2.32.4:[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━\u001b[0m \u001b[32m22/31\u001b[0m [triton]\n",
      "\u001b[2K      Successfully uninstalled requests-2.32.4\u001b[90m━━━━━━━━━━━\u001b[0m \u001b[32m22/31\u001b[0m [triton]\n",
      "\u001b[2K  Attempting uninstall: jinja2━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━\u001b[0m \u001b[32m25/31\u001b[0m [nvidia-cudnn-cu12]12]\n",
      "\u001b[2K    Found existing installation: Jinja2 3.1.6╺\u001b[0m\u001b[90m━━━━━━━\u001b[0m \u001b[32m25/31\u001b[0m [nvidia-cudnn-cu12]\n",
      "\u001b[2K    Uninstalling Jinja2-3.1.6:━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━\u001b[0m \u001b[32m25/31\u001b[0m [nvidia-cudnn-cu12]\n",
      "\u001b[2K      Successfully uninstalled Jinja2-3.1.60m╺\u001b[0m\u001b[90m━━━━━━━\u001b[0m \u001b[32m25/31\u001b[0m [nvidia-cudnn-cu12]\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m31/31\u001b[0m [torchtext]31\u001b[0m [torchtext]olver-cu12]\n",
      "\u001b[1A\u001b[2K\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "jupyterlab 4.4.3 requires httpx>=0.25.0, which is not installed.\n",
      "captum 0.8.0 requires numpy<2.0, but you have numpy 2.2.6 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed MarkupSafe-3.0.2 certifi-2025.7.14 charset_normalizer-3.4.2 filelock-3.18.0 fsspec-2025.7.0 idna-3.10 jinja2-3.1.6 mpmath-1.3.0 networkx-3.4.2 numpy-2.2.6 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.18.1 nvidia-nvjitlink-cu12-12.9.86 nvidia-nvtx-cu12-12.1.105 requests-2.32.4 sympy-1.14.0 torch-2.1.0 torchdata-0.7.0 torchtext-0.16.0 tqdm-4.67.1 triton-2.1.0 typing-extensions-4.14.1 urllib3-2.5.0\n",
      "Collecting numpy==1.26.4\n",
      "  Downloading numpy-1.26.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
      "Downloading numpy-1.26.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.2/18.2 MB\u001b[0m \u001b[31m245.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: numpy\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 2.2.6\n",
      "    Uninstalling numpy-2.2.6:\n",
      "      Successfully uninstalled numpy-2.2.6\n",
      "Successfully installed numpy-1.26.4\n",
      "Collecting spacy\n",
      "  Downloading spacy-3.8.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (27 kB)\n",
      "Collecting spacy-legacy<3.1.0,>=3.0.11 (from spacy)\n",
      "  Downloading spacy_legacy-3.0.12-py2.py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting spacy-loggers<2.0.0,>=1.0.0 (from spacy)\n",
      "  Downloading spacy_loggers-1.0.5-py3-none-any.whl.metadata (23 kB)\n",
      "Collecting murmurhash<1.1.0,>=0.28.0 (from spacy)\n",
      "  Downloading murmurhash-1.0.13-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.2 kB)\n",
      "Collecting cymem<2.1.0,>=2.0.2 (from spacy)\n",
      "  Downloading cymem-2.0.11-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.5 kB)\n",
      "Collecting preshed<3.1.0,>=3.0.2 (from spacy)\n",
      "  Downloading preshed-3.0.10-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.4 kB)\n",
      "Collecting thinc<8.4.0,>=8.3.4 (from spacy)\n",
      "  Downloading thinc-8.3.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (15 kB)\n",
      "Collecting wasabi<1.2.0,>=0.9.1 (from spacy)\n",
      "  Downloading wasabi-1.1.3-py3-none-any.whl.metadata (28 kB)\n",
      "Collecting srsly<3.0.0,>=2.4.3 (from spacy)\n",
      "  Downloading srsly-2.5.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (19 kB)\n",
      "Collecting catalogue<2.1.0,>=2.0.6 (from spacy)\n",
      "  Downloading catalogue-2.0.10-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting weasel<0.5.0,>=0.1.0 (from spacy)\n",
      "  Downloading weasel-0.4.1-py3-none-any.whl.metadata (4.6 kB)\n",
      "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from spacy) (0.16.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from spacy) (4.67.1)\n",
      "Requirement already satisfied: numpy>=1.19.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from spacy) (1.26.4)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from spacy) (2.32.4)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from spacy) (2.9.2)\n",
      "Requirement already satisfied: jinja2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from spacy) (3.1.6)\n",
      "Requirement already satisfied: setuptools in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from spacy) (80.9.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from spacy) (24.2)\n",
      "Collecting langcodes<4.0.0,>=3.2.0 (from spacy)\n",
      "  Downloading langcodes-3.5.0-py3-none-any.whl.metadata (29 kB)\n",
      "Collecting language-data>=1.2 (from langcodes<4.0.0,>=3.2.0->spacy)\n",
      "  Downloading language_data-1.3.0-py3-none-any.whl.metadata (4.3 kB)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.23.4)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.14.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2025.7.14)\n",
      "Collecting blis<1.4.0,>=1.3.0 (from thinc<8.4.0,>=8.3.4->spacy)\n",
      "  Downloading blis-1.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.4 kB)\n",
      "Collecting confection<1.0.0,>=0.0.1 (from thinc<8.4.0,>=8.3.4->spacy)\n",
      "  Downloading confection-0.1.5-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting numpy>=1.19.0 (from spacy)\n",
      "  Downloading numpy-2.2.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (62 kB)\n",
      "Requirement already satisfied: click>=8.0.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from typer<1.0.0,>=0.3.0->spacy) (8.1.8)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from typer<1.0.0,>=0.3.0->spacy) (14.0.0)\n",
      "Collecting cloudpathlib<1.0.0,>=0.7.0 (from weasel<0.5.0,>=0.1.0->spacy)\n",
      "  Downloading cloudpathlib-0.21.1-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting smart-open<8.0.0,>=5.2.1 (from weasel<0.5.0,>=0.1.0->spacy)\n",
      "  Downloading smart_open-7.3.0.post1-py3-none-any.whl.metadata (24 kB)\n",
      "Collecting wrapt (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy)\n",
      "  Downloading wrapt-1.17.2-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.4 kB)\n",
      "Collecting marisa-trie>=1.1.0 (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy)\n",
      "  Downloading marisa_trie-1.2.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.0 kB)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.19.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from jinja2->spacy) (3.0.2)\n",
      "Downloading spacy-3.8.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (31.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m31.5/31.5 MB\u001b[0m \u001b[31m268.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading catalogue-2.0.10-py3-none-any.whl (17 kB)\n",
      "Downloading cymem-2.0.11-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (204 kB)\n",
      "Downloading langcodes-3.5.0-py3-none-any.whl (182 kB)\n",
      "Downloading murmurhash-1.0.13-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (117 kB)\n",
      "Downloading preshed-3.0.10-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (795 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m795.1/795.1 kB\u001b[0m \u001b[31m631.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading spacy_legacy-3.0.12-py2.py3-none-any.whl (29 kB)\n",
      "Downloading spacy_loggers-1.0.5-py3-none-any.whl (22 kB)\n",
      "Downloading srsly-2.5.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m681.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading thinc-8.3.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.1/4.1 MB\u001b[0m \u001b[31m383.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading blis-1.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.5/11.5 MB\u001b[0m \u001b[31m331.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading confection-0.1.5-py3-none-any.whl (35 kB)\n",
      "Downloading numpy-2.2.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.8/16.8 MB\u001b[0m \u001b[31m377.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading wasabi-1.1.3-py3-none-any.whl (27 kB)\n",
      "Downloading weasel-0.4.1-py3-none-any.whl (50 kB)\n",
      "Downloading cloudpathlib-0.21.1-py3-none-any.whl (52 kB)\n",
      "Downloading smart_open-7.3.0.post1-py3-none-any.whl (61 kB)\n",
      "Downloading language_data-1.3.0-py3-none-any.whl (5.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m265.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading marisa_trie-1.2.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m683.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading wrapt-1.17.2-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (82 kB)\n",
      "Installing collected packages: cymem, wrapt, wasabi, spacy-loggers, spacy-legacy, numpy, murmurhash, marisa-trie, cloudpathlib, catalogue, srsly, smart-open, preshed, language-data, blis, langcodes, confection, weasel, thinc, spacy\n",
      "\u001b[2K  Attempting uninstall: numpy0m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 2/20\u001b[0m [wasabi]\n",
      "\u001b[2K    Found existing installation: numpy 1.26.4━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 2/20\u001b[0m [wasabi]\n",
      "\u001b[2K    Uninstalling numpy-1.26.4:0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 5/20\u001b[0m [numpy]\n",
      "\u001b[2K      Successfully uninstalled numpy-1.26.4━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 5/20\u001b[0m [numpy]\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20/20\u001b[0m [spacy]m19/20\u001b[0m [spacy]]es]ata]\n",
      "\u001b[1A\u001b[2K\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "captum 0.8.0 requires numpy<2.0, but you have numpy 2.2.6 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed blis-1.3.0 catalogue-2.0.10 cloudpathlib-0.21.1 confection-0.1.5 cymem-2.0.11 langcodes-3.5.0 language-data-1.3.0 marisa-trie-1.2.1 murmurhash-1.0.13 numpy-2.2.6 preshed-3.0.10 smart-open-7.3.0.post1 spacy-3.8.7 spacy-legacy-3.0.12 spacy-loggers-1.0.5 srsly-2.5.1 thinc-8.3.6 wasabi-1.1.3 weasel-0.4.1 wrapt-1.17.2\n",
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.2.6 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/runpy.py\", line 187, in _run_module_as_main\n",
      "    mod_name, mod_spec, code = _get_module_details(mod_name, _Error)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/runpy.py\", line 146, in _get_module_details\n",
      "    return _get_module_details(pkg_main_name, error)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/runpy.py\", line 110, in _get_module_details\n",
      "    __import__(pkg_name)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/spacy/__init__.py\", line 6, in <module>\n",
      "    from .errors import setup_default_warnings\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/spacy/errors.py\", line 3, in <module>\n",
      "    from .compat import Literal\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/spacy/compat.py\", line 4, in <module>\n",
      "    from thinc.util import copy_array\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/thinc/__init__.py\", line 5, in <module>\n",
      "    from .config import registry\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/thinc/config.py\", line 5, in <module>\n",
      "    from .types import Decorator\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/thinc/types.py\", line 27, in <module>\n",
      "    from .compat import cupy, has_cupy\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/thinc/compat.py\", line 35, in <module>\n",
      "    import torch\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/torch/__init__.py\", line 1382, in <module>\n",
      "    from .functional import *  # noqa: F403\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/torch/functional.py\", line 7, in <module>\n",
      "    import torch.nn.functional as F\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/torch/nn/__init__.py\", line 1, in <module>\n",
      "    from .modules import *  # noqa: F403\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/torch/nn/modules/__init__.py\", line 35, in <module>\n",
      "    from .transformer import TransformerEncoder, TransformerDecoder, \\\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/torch/nn/modules/transformer.py\", line 20, in <module>\n",
      "    device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/torch/nn/modules/transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:84.)\n",
      "  device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "Collecting de-core-news-sm==3.8.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/de_core_news_sm-3.8.0/de_core_news_sm-3.8.0-py3-none-any.whl (14.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.6/14.6 MB\u001b[0m \u001b[31m86.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: de-core-news-sm\n",
      "Successfully installed de-core-news-sm-3.8.0\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('de_core_news_sm')\n",
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.2.6 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/runpy.py\", line 187, in _run_module_as_main\n",
      "    mod_name, mod_spec, code = _get_module_details(mod_name, _Error)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/runpy.py\", line 146, in _get_module_details\n",
      "    return _get_module_details(pkg_main_name, error)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/runpy.py\", line 110, in _get_module_details\n",
      "    __import__(pkg_name)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/spacy/__init__.py\", line 6, in <module>\n",
      "    from .errors import setup_default_warnings\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/spacy/errors.py\", line 3, in <module>\n",
      "    from .compat import Literal\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/spacy/compat.py\", line 4, in <module>\n",
      "    from thinc.util import copy_array\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/thinc/__init__.py\", line 5, in <module>\n",
      "    from .config import registry\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/thinc/config.py\", line 5, in <module>\n",
      "    from .types import Decorator\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/thinc/types.py\", line 27, in <module>\n",
      "    from .compat import cupy, has_cupy\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/thinc/compat.py\", line 35, in <module>\n",
      "    import torch\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/torch/__init__.py\", line 1382, in <module>\n",
      "    from .functional import *  # noqa: F403\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/torch/functional.py\", line 7, in <module>\n",
      "    import torch.nn.functional as F\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/torch/nn/__init__.py\", line 1, in <module>\n",
      "    from .modules import *  # noqa: F403\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/torch/nn/modules/__init__.py\", line 35, in <module>\n",
      "    from .transformer import TransformerEncoder, TransformerDecoder, \\\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/torch/nn/modules/transformer.py\", line 20, in <module>\n",
      "    device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/torch/nn/modules/transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:84.)\n",
      "  device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "Collecting en-core-web-sm==3.8.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m150.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: en-core-web-sm\n",
      "Successfully installed en-core-web-sm-3.8.0\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n",
      "Collecting sacrebleu\n",
      "  Downloading sacrebleu-2.5.1-py3-none-any.whl.metadata (51 kB)\n",
      "Collecting portalocker (from sacrebleu)\n",
      "  Downloading portalocker-3.2.0-py3-none-any.whl.metadata (8.7 kB)\n",
      "Requirement already satisfied: regex in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sacrebleu) (2024.11.6)\n",
      "Requirement already satisfied: tabulate>=0.8.9 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sacrebleu) (0.9.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sacrebleu) (2.2.6)\n",
      "Requirement already satisfied: colorama in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sacrebleu) (0.4.6)\n",
      "Collecting lxml (from sacrebleu)\n",
      "  Downloading lxml-6.0.0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (6.6 kB)\n",
      "Downloading sacrebleu-2.5.1-py3-none-any.whl (104 kB)\n",
      "Downloading lxml-6.0.0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (5.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.2/5.2 MB\u001b[0m \u001b[31m152.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading portalocker-3.2.0-py3-none-any.whl (22 kB)\n",
      "Installing collected packages: portalocker, lxml, sacrebleu\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3/3\u001b[0m [sacrebleu]/3\u001b[0m [sacrebleu]\n",
      "\u001b[1A\u001b[2KSuccessfully installed lxml-6.0.0 portalocker-3.2.0 sacrebleu-2.5.1\n",
      "Collecting portalocker\n",
      "  Downloading portalocker-3.2.0-py3-none-any.whl.metadata (8.7 kB)\n",
      "Downloading portalocker-3.2.0-py3-none-any.whl (22 kB)\n",
      "Installing collected packages: portalocker\n",
      "  Attempting uninstall: portalocker\n",
      "    Found existing installation: portalocker 3.2.0\n",
      "    Uninstalling portalocker-3.2.0:\n",
      "      Successfully uninstalled portalocker-3.2.0\n",
      "Successfully installed portalocker-3.2.0\n",
      "Collecting sagemaker\n",
      "  Downloading sagemaker-2.248.1-py3-none-any.whl.metadata (17 kB)\n",
      "Requirement already satisfied: attrs<26,>=24 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker) (25.3.0)\n",
      "Requirement already satisfied: boto3<2.0,>=1.35.75 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker) (1.38.38)\n",
      "Requirement already satisfied: cloudpickle>=2.2.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker) (3.1.1)\n",
      "Requirement already satisfied: docker in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker) (7.1.0)\n",
      "Requirement already satisfied: fastapi in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker) (0.115.13)\n",
      "Requirement already satisfied: google-pasta in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker) (0.2.0)\n",
      "Requirement already satisfied: graphene<4,>=3 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker) (3.4.3)\n",
      "Requirement already satisfied: importlib-metadata<7.0,>=1.4.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker) (6.11.0)\n",
      "Requirement already satisfied: jsonschema in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker) (4.24.0)\n",
      "Collecting numpy==1.26.4 (from sagemaker)\n",
      "  Downloading numpy-1.26.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
      "Requirement already satisfied: omegaconf<3,>=2.2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker) (2.3.0)\n",
      "Requirement already satisfied: packaging<25,>=23.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker) (24.2)\n",
      "Requirement already satisfied: pandas in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker) (2.3.0)\n",
      "Requirement already satisfied: pathos in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker) (0.3.4)\n",
      "Requirement already satisfied: platformdirs in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker) (4.3.8)\n",
      "Requirement already satisfied: protobuf<6.32,>=3.12 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker) (4.25.3)\n",
      "Requirement already satisfied: psutil in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker) (6.1.1)\n",
      "Requirement already satisfied: pyyaml>=6.0.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker) (6.0.2)\n",
      "Requirement already satisfied: requests in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker) (2.32.4)\n",
      "Requirement already satisfied: sagemaker-core<2.0.0,>=1.0.17 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker) (1.0.38)\n",
      "Requirement already satisfied: schema in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker) (0.7.7)\n",
      "Requirement already satisfied: smdebug-rulesconfig==1.0.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker) (1.0.1)\n",
      "Requirement already satisfied: tblib<4,>=1.7.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker) (3.1.0)\n",
      "Requirement already satisfied: tqdm in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker) (4.67.1)\n",
      "Requirement already satisfied: urllib3<3.0.0,>=1.26.8 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker) (2.5.0)\n",
      "Requirement already satisfied: uvicorn in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker) (0.34.3)\n",
      "Requirement already satisfied: botocore<1.39.0,>=1.38.38 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from boto3<2.0,>=1.35.75->sagemaker) (1.38.38)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from boto3<2.0,>=1.35.75->sagemaker) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.14.0,>=0.13.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from boto3<2.0,>=1.35.75->sagemaker) (0.13.0)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from botocore<1.39.0,>=1.38.38->boto3<2.0,>=1.35.75->sagemaker) (2.9.0)\n",
      "Requirement already satisfied: graphql-core<3.3,>=3.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from graphene<4,>=3->sagemaker) (3.2.6)\n",
      "Requirement already satisfied: graphql-relay<3.3,>=3.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from graphene<4,>=3->sagemaker) (3.2.0)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from graphene<4,>=3->sagemaker) (4.14.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from importlib-metadata<7.0,>=1.4.0->sagemaker) (3.23.0)\n",
      "Requirement already satisfied: antlr4-python3-runtime==4.9.* in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from omegaconf<3,>=2.2->sagemaker) (4.9.3)\n",
      "Requirement already satisfied: six>=1.5 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.39.0,>=1.38.38->boto3<2.0,>=1.35.75->sagemaker) (1.17.0)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.0.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker-core<2.0.0,>=1.0.17->sagemaker) (2.9.2)\n",
      "Requirement already satisfied: rich<15.0.0,>=14.0.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker-core<2.0.0,>=1.0.17->sagemaker) (14.0.0)\n",
      "Requirement already satisfied: mock<5.0,>4.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker-core<2.0.0,>=1.0.17->sagemaker) (4.0.3)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from jsonschema->sagemaker) (2025.4.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from jsonschema->sagemaker) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from jsonschema->sagemaker) (0.25.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.0.0->sagemaker-core<2.0.0,>=1.0.17->sagemaker) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.0.0->sagemaker-core<2.0.0,>=1.0.17->sagemaker) (2.23.4)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from rich<15.0.0,>=14.0.0->sagemaker-core<2.0.0,>=1.0.17->sagemaker) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from rich<15.0.0,>=14.0.0->sagemaker-core<2.0.0,>=1.0.17->sagemaker) (2.19.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich<15.0.0,>=14.0.0->sagemaker-core<2.0.0,>=1.0.17->sagemaker) (0.1.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests->sagemaker) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests->sagemaker) (3.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests->sagemaker) (2025.7.14)\n",
      "Requirement already satisfied: starlette<0.47.0,>=0.40.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from fastapi->sagemaker) (0.46.2)\n",
      "Requirement already satisfied: anyio<5,>=3.6.2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from starlette<0.47.0,>=0.40.0->fastapi->sagemaker) (4.9.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from anyio<5,>=3.6.2->starlette<0.47.0,>=0.40.0->fastapi->sagemaker) (1.3.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from anyio<5,>=3.6.2->starlette<0.47.0,>=0.40.0->fastapi->sagemaker) (1.3.1)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from pandas->sagemaker) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from pandas->sagemaker) (2025.2)\n",
      "Requirement already satisfied: ppft>=1.7.7 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from pathos->sagemaker) (1.7.7)\n",
      "Requirement already satisfied: dill>=0.4.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from pathos->sagemaker) (0.4.0)\n",
      "Requirement already satisfied: pox>=0.3.6 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from pathos->sagemaker) (0.3.6)\n",
      "Requirement already satisfied: multiprocess>=0.70.18 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from pathos->sagemaker) (0.70.18)\n",
      "Requirement already satisfied: click>=7.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from uvicorn->sagemaker) (8.1.8)\n",
      "Requirement already satisfied: h11>=0.8 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from uvicorn->sagemaker) (0.16.0)\n",
      "Downloading sagemaker-2.248.1-py3-none-any.whl (1.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m44.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading numpy-1.26.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.2/18.2 MB\u001b[0m \u001b[31m192.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: numpy, sagemaker\n",
      "\u001b[2K  Attempting uninstall: numpy\n",
      "\u001b[2K    Found existing installation: numpy 2.2.6\n",
      "\u001b[2K    Uninstalling numpy-2.2.6:\n",
      "\u001b[2K      Successfully uninstalled numpy-2.2.6\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2/2\u001b[0m [sagemaker]/2\u001b[0m [sagemaker]\n",
      "\u001b[1A\u001b[2K\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed numpy-1.26.4 sagemaker-2.248.1\n"
     ]
    }
   ],
   "source": [
    "# !pip install torchtext==0.16.0 --no-cache-dir\n",
    "# !pip install spacy\n",
    "# !python -m spacy download de_core_news_sm\n",
    "# !python -m spacy download en_core_web_sm\n",
    "# !pip install sacrebleu\n",
    "# !pip install --upgrade --force-reinstall portalocker\n",
    "\n",
    "\n",
    "\n",
    "!pip uninstall -y torch torchtext torchaudio torchvision spacy thinc numpy sagemaker transformers\n",
    "!pip install torch==2.1.0 torchtext==0.16.0 --force-reinstall --no-cache-dir\n",
    "!pip install numpy==1.26.4 --force-reinstall --no-cache-dir\n",
    "!pip install spacy --no-cache-dir\n",
    "!python -m spacy download de_core_news_sm\n",
    "!python -m spacy download en_core_web_sm\n",
    "\n",
    "# 6. Install other dependencies\n",
    "!pip install sacrebleu --no-cache-dir\n",
    "!pip install --upgrade --force-reinstall portalocker --no-cache-dir\n",
    "!pip install sagemaker # Ensure sagemaker is compatible with numpy 1.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "SMdXQ-q_OLa3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/ec2-user/.config/sagemaker/config.yaml\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "from torchtext.datasets import Multi30k\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import random\n",
    "import sys\n",
    "import time\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from torchtext.data.metrics import bleu_score\n",
    "\n",
    "\n",
    "import sagemaker\n",
    "import boto3\n",
    "import os\n",
    "import torch\n",
    "from sagemaker.s3 import S3Uploader \n",
    "import tempfile # For safe temporary file creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b5M25lveO3-f",
    "outputId": "5577f84b-d84a-4a14-bc03-b9ea005768ee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.0+cu121\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "jc-Bj1SEN30t"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "For understanding purpose lets take \"Cat Loves Milk\" as an input instance in the first batch of 32 samples\n",
    "\n",
    "Let's assume:\n",
    "\n",
    "Batch size (N) = 32\n",
    "1st Sentence: \"Cat Loves Milk\"\n",
    "Number of words (seq_len) = 24 (max_len of a sentence in the batch)\n",
    "Encoder\n",
    "   Input: ([<bos>,\"Cat\", \"Loves\", \"Milk\",<eos> , <pad>,....]) -> value_len = key_len = query_len = max_len = 24\n",
    "Decoder\n",
    "   Input: ([<bos>,\"Katze\", \"liebt\", \"Milch\", <pad>,....]) -> value_len = key_len = query_len = max_len = 23 NO <eos> ONLY <bos>\n",
    "   Target: ([\"Katze\", \"liebt\", \"Milch\", <eos>, <pad>, ...]) -> value_len = key_len = query_len = max_len = 23 NO <bos> ONLY <eos>\n",
    "   i.e. a shift of token happens for decoder to predict the next word which is the target\n",
    "\n",
    "Embedding size (embed_size) = 512\n",
    "Number of heads (heads) = 8\n",
    "Head dimension (head_dim) = embed_size / heads = 512 / 8 = 64\n",
    "\"\"\"\n",
    "\n",
    "class SelfAttention(nn.Module):\n",
    "    def __init__(self, embed_size, heads):\n",
    "        super().__init__()\n",
    "        self.embed_size = embed_size\n",
    "        self.heads = heads\n",
    "        self.head_dim = embed_size//heads\n",
    "\n",
    "        assert(self.head_dim * heads == embed_size), \"Embed size needs to be div by heads\"\n",
    "\n",
    "        # Each of these is a learnable weight matrix\n",
    "        self.values = nn.Linear(embed_size, embed_size) # W_V (512*512 Matrix)\n",
    "        self.keys = nn.Linear(embed_size, embed_size) # W_K (512*512 Matrix)\n",
    "        self.queries = nn.Linear(embed_size, embed_size) # W_Q (512*512 Matrix)\n",
    "        self.fc_out = nn.Linear(embed_size, embed_size) # W_O (512*512 Matrix)\n",
    "\n",
    "    def forward(self, values, keys, query, mask):\n",
    "        N = query.shape[0] # Number of Training Examples -> N = 32 in our case\n",
    "        value_len, key_len, query_len = values.shape[1], keys.shape[1], query.shape[1]  # 24 (23 when self attention called in Decoder) each sample length in the batch\n",
    "        # Difference in Query shape and key,value shape by 1 is observed when the attention is called in Decoder AFTER masked multi head self attention i.e. at cross attention\n",
    "\n",
    "        values = self.values(values)   # (N, value_len, embed_size) # (32, 24, 512) -> (32, 24, 512)\n",
    "        keys = self.keys(keys)  # (N, key_len, embed_size)  # (32, 24, 512) -> (32, 24, 512)\n",
    "        queries = self.queries(query)   # (N, query_len, embed_size)  # (32, 24 or (23 @cross atention), 512) -> (32, 24 or (23), 512)\n",
    "\n",
    "\n",
    "        # Reshape into multiple heads\n",
    "        values = values.reshape(N, value_len, self.heads, self.head_dim) # (32, 24, 8 , 64) nvhd\n",
    "        keys = keys.reshape(N, key_len, self.heads, self.head_dim) # (32, 24, 8 , 64) nkhd\n",
    "        queries = queries.reshape(N, query_len, self.heads, self.head_dim) # (32, 24, 8 , 64) nqhd\n",
    "\n",
    "\n",
    "        # Einsum does matrix multiplication. for query*keys for each training example\n",
    "        energy = torch.einsum(\"nqhd,nkhd -> nhqk\", [queries, keys]) # (32, 8, 24, 24)\n",
    "        # Dot product each query with each key.\n",
    "        #   - We get a 24*24 (like a covariance matrix) in encoder self attention.\n",
    "        #   - We get a 23*23 (like a covariance matrix) in decoder self attention.\n",
    "        #   - We get a 23*24 (like a covariance matrix) in decoder cross attention.\n",
    "\n",
    "        # This for each head. (8,24,24). On all samples in batch. (32,8,24,24)\n",
    "\n",
    "        # Mask padded indices so their weights become close to 0   # (32, 8, 24, 24)\n",
    "        if mask is not None:\n",
    "\n",
    "            energy = energy.masked_fill(mask == 0, float(\"-1e20\"))\n",
    "\n",
    "\n",
    "        # Normalize energy values similarly to so that they sum to 1. Also divide by scaling factor for better stability\n",
    "        attention = torch.softmax(energy/ (self.head_dim ** (1/2)), dim=3) # (N, heads, query_len, key_len)\n",
    "        # dim = 3 indicating we operate along row across columns i.e.on query for each key\n",
    "\n",
    "        out = torch.einsum(\"nhqk,nvhd->nqhd\",[attention, values]) # multiplies attention scores with values. #(32, 8, 24, 24) @ (32, 24, 8, 64) → (32, 24, 8, 64)\n",
    "        out = self.fc_out(out.reshape(N, query_len, self.heads * self.head_dim )) # (32, 24 (23 in decoder), 512) # Flatten the last dimensions and send it to fc_out -> # (N, query_len, embed_size)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "\n",
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, embed_size, heads, dropout, forward_expansion):\n",
    "        super().__init__()\n",
    "        self.attention = SelfAttention(embed_size, heads)\n",
    "        self.norm1 = nn.LayerNorm(embed_size)\n",
    "        self.norm2 = nn.LayerNorm(embed_size)\n",
    "\n",
    "        self.feed_forward = nn.Sequential(\n",
    "            nn.Linear(embed_size, forward_expansion*embed_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(forward_expansion*embed_size, embed_size)\n",
    "        )\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, value, key, query, mask):\n",
    "\n",
    "        \"\"\"attention = self.attention(value, key, query, mask)\n",
    "        x = self.dropout(self.norm1(query + attention)) # Add skip connection, run through normalization and finally dropout\n",
    "        forward = self.feed_forward(x)\n",
    "        out = self.dropout(self.norm2(x + forward))\"\"\"\n",
    "\n",
    "\n",
    "        # Below is the Pre-LN implementation\n",
    "        attention = self.attention(self.norm1(value), self.norm1(key), self.norm1(query), mask) # Apply self-attention\n",
    "        x = query + self.dropout(attention)  # Skip connection with original query and dropout\n",
    "        forward = self.norm2(x)  # Normalize before feedforward\n",
    "        out = x + self.dropout(self.feed_forward(forward))\n",
    "\n",
    "        return out # (32,24 (23 @ Decoder),512)\n",
    "\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        src_vocab_size,  # Total vocabulary size (number of unique words)\n",
    "        embed_size,      # Dimension of each word embedding # 512\n",
    "        num_layers,      # Number of Transformer blocks # 6\n",
    "        heads,           # Number of self-attention heads # 8\n",
    "        device,          # GPU/CPU device\n",
    "        forward_expansion,  # Expansion factor for the feed-forward layer\n",
    "        dropout,         # Dropout rate\n",
    "        max_length,      # Maximum sentence length\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.embed_size = embed_size\n",
    "        self.device = device\n",
    "        self.word_embedding = nn.Embedding(src_vocab_size, embed_size) # Converts tokenized words into dense embeddings. i.e. each word willl be represented as embedding 1D vector -> 2D vector\n",
    "        self.position_embedding = nn.Embedding(max_length, embed_size) # Adds position information (since Transformers have no recurrence).\n",
    "\n",
    "        self.layers = nn.ModuleList(\n",
    "            [\n",
    "                TransformerBlock(\n",
    "                    embed_size,\n",
    "                    heads,\n",
    "                    dropout = dropout,\n",
    "                    forward_expansion=forward_expansion\n",
    "                    )\n",
    "                for _ in range(num_layers)\n",
    "                ])\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x, mask):\n",
    "        N, seq_length = x.shape #(32,24) # Here x is tokenized representations of Our data # Ex: [\"Cat\",\"Loves\",\"Milk\"] -> [2(bos),7,8,9,3(eos),1(pad),1,...]. Assume N = 32 (batch), seq_length = 24 (words)\n",
    "        positions = torch.arange(0, seq_length).expand(N, seq_length).to(self.device) #Adding positions with numbers for batch size (32,24)\n",
    "        out = self.dropout(self.word_embedding(x) + self.position_embedding(positions)) # (32,24,512) + (32,24,512) Making the positions learnable by creating embeddings to them\n",
    "        # word embedding (\"2\") returns a 512 dimensional vector\n",
    "        for layer in self.layers:\n",
    "            out = layer(out, out, out, mask) # value, key, query (32,24,512), mask (32,1,1,24) which are the input for forward in Transformer Encoder self attention Block\n",
    "            # So masking is done only on the columns i.e. last index. Specifically on the padded indexs\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class DecoderBlock(nn.Module):\n",
    "    def __init__(self, embed_size, heads, dropout, forward_expansion ):\n",
    "        super().__init__()\n",
    "        self.norm = nn.LayerNorm(embed_size)\n",
    "        self.attention = SelfAttention(embed_size, heads) # Masked Self-Attention\n",
    "        self.transformer_block = TransformerBlock(embed_size, heads, dropout = dropout, forward_expansion = forward_expansion) # Cross-Attention + Feedforward\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, value, key, x, src_mask, trg_mask):\n",
    "        #print(\"Here at Decoder Block sending trg_mask\")\n",
    "        attention = self.attention(self.norm(x), self.norm(x), self.norm(x), trg_mask) # Masked Attention -> (Lower Triangular Mask + padded Tokens Mask) = trg_mask\n",
    "        query = x + self.dropout(attention)\n",
    "        out = self.transformer_block(value, key, query, src_mask) # Just padding Tokens Mask like Encoder Mask\n",
    "\n",
    "        \"\"\"# Post LN Implementation\n",
    "        attention = self.attention(x, x, x, trg_mask) #Uses self-attention where query = key = value = x (decoder’s past words).            # Uses trg_mask → Ensures that each word only attends to past words (not future words).\n",
    "        query = self.dropout(self.norm(attention + x))\n",
    "        out = self.transformer_block(value, key, query, src_mask)\"\"\"\n",
    "        return out\n",
    "\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            trg_vocab_size,  # Target vocabulary size\n",
    "            embed_size,      # Dimension of each word embedding # 8\n",
    "            num_layers,      # Number of Transformer blocks\n",
    "            heads,           # Number of self-attention heads\n",
    "            device,          # GPU/CPU device\n",
    "            forward_expansion,  # Expansion factor for the feed-forward layer\n",
    "            dropout,         # Dropout rate\n",
    "            max_length,      # Maximum sentence length\n",
    "        ):\n",
    "        super().__init__()\n",
    "        self.embed_size = embed_size\n",
    "        self.device = device\n",
    "        self.word_embedding = nn.Embedding(trg_vocab_size, embed_size) # Converts tokenized words into dense embeddings.\n",
    "        self.position_embedding = nn.Embedding(max_length, embed_size) # Adds position information (since Transformers have no recurrence).\n",
    "\n",
    "        self.layers = nn.ModuleList(\n",
    "            [\n",
    "                DecoderBlock(\n",
    "                    embed_size,\n",
    "                    heads,\n",
    "                    dropout = dropout,\n",
    "                    forward_expansion=forward_expansion\n",
    "                    )\n",
    "                for _ in range(num_layers)\n",
    "                ])\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.fc_out = nn.Linear(embed_size, trg_vocab_size) # Projects the decoder output into target vocabulary scores\n",
    "\n",
    "\n",
    "    def forward(self, x, enc_out, src_mask, trg_mask):\n",
    "        N, seq_length = x.shape  # Here x is tokenized representations of Our data # Ex: ['Katze', 'liebt', 'Milch'] -> [2(bos),7,15,18,1(pad),1,...]. Assume N = 32 (batch), seq_length = 23 (words)\n",
    "        positions = torch.arange(0, seq_length).expand(N, seq_length).to(self.device)  #(32,23)\n",
    "        x = self.dropout(self.word_embedding(x) + self.position_embedding(positions)) # (32,23,512) + (32,23,512)\n",
    "        # word embedding (\"2\") returns a 512 dimensional vector\n",
    "        for layer in self.layers:\n",
    "            x = layer(enc_out, enc_out, x, src_mask, trg_mask) # value(32, 23 (24 @ Cross Attention), 512), key(32, 23 (24 @ Cross Attention), 512), query (32, 23, 512), mask (32, 1, 23, 23) which are the input for forward in Transformer Block\n",
    "\n",
    "        out = self.fc_out(x) # (32, 23, 512) -> (32,23,trg_vocab_size) logit vectors, where each logit corresponds to the probability of a word in the target vocabulary.\n",
    "        return out\n",
    "\n",
    "class Transformer(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        src_vocab_size,\n",
    "        trg_vocab_size,\n",
    "        src_pad_idx,\n",
    "        trg_pad_idx,\n",
    "        embed_size=512,\n",
    "        num_layers=6,\n",
    "        forward_expansion=4,\n",
    "        heads=8,\n",
    "        dropout=0.0,\n",
    "        device=\"cpu\",\n",
    "        max_length=100,\n",
    "    ):\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        self.encoder = Encoder(\n",
    "            src_vocab_size,\n",
    "            embed_size,\n",
    "            num_layers,\n",
    "            heads,\n",
    "            device,\n",
    "            forward_expansion,\n",
    "            dropout,\n",
    "            max_length,\n",
    "        )\n",
    "\n",
    "        self.decoder = Decoder(\n",
    "            trg_vocab_size,\n",
    "            embed_size,\n",
    "            num_layers,\n",
    "            heads,\n",
    "            device,\n",
    "            forward_expansion,\n",
    "            dropout,\n",
    "            max_length,\n",
    "        )\n",
    "\n",
    "        self.src_pad_idx = src_pad_idx\n",
    "        self.trg_pad_idx = trg_pad_idx\n",
    "        self.device = device\n",
    "        for p in self.parameters():\n",
    "            if p.dim() > 1:\n",
    "                nn.init.xavier_uniform_(p)\n",
    "\n",
    "\n",
    "    def make_src_mask(self, src):\n",
    "        src_mask = (src != self.src_pad_idx).unsqueeze(1).unsqueeze(2)\n",
    "\n",
    "        # (N = src.shape[0], 1, 1, src.shape[1])\n",
    "\n",
    "        #tensor([[[[ True,  True,  True,  ..., True,  True,  True,  True]]],   The Cat was trying to.....in the house <eos>\n",
    "        #                                 .\n",
    "        #                                 .\n",
    "        #                                 .\n",
    "        #[[[ True,  True, True, False, False, False, False]]]])         Cats Love Milk <eos> <pad>......<pad> <pad>\n",
    "\n",
    "        return src_mask.to(self.device)\n",
    "\n",
    "\n",
    "    def make_trg_mask(self, trg):\n",
    "        N, trg_len = trg.shape\n",
    "        # 1. Causal (Look-Ahead) Mask (lower triangular, prevents attending to future tokens)\n",
    "        causal_mask = torch.tril(torch.ones((trg_len, trg_len), device=self.device)).bool() # Shape: (trg_len, trg_len) e.g., (23, 23)\n",
    "\n",
    "        # 2. Target Padding Mask (prevents attending to <pad> tokens in the target sequence itself) This is similar to src_mask, but for the target sequence.\n",
    "        padding_mask = (trg != self.trg_pad_idx).unsqueeze(1).unsqueeze(2).bool()# Shape: (N, 1, 1, trg_len) e.g., (32, 1, 1, 23)\n",
    "\n",
    "        # 3. Combine them using logical AND (position is True only if BOTH are True)\n",
    "        combined_mask = causal_mask.unsqueeze(0).unsqueeze(0) & padding_mask # (32, 1, 23, 23)\n",
    "        return combined_mask.to(self.device)\n",
    "\n",
    "\n",
    "    def forward(self, src, trg):\n",
    "        src_mask = self.make_src_mask(src) #(32,1,1,24) Booleans # To not consider any padding values\n",
    "        trg_mask = self.make_trg_mask(trg) # (32,1,23,23)  Ones and Zeros # Lower Triangualr matrix to not allow peeking and not attending to padded tokens\n",
    "        enc_src = self.encoder(src, src_mask)\n",
    "        out = self.decoder(trg, enc_src, src_mask, trg_mask)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to yield tokens (for vocab building) sepearate for each vocabulary\n",
    "def yield_tokens(data, tokenizer, lang=\"en\"):\n",
    "    for src_text, tgt_text in data:\n",
    "        text = src_text if lang == \"en\" else tgt_text  # Choose English or German text\n",
    "        yield tokenizer(text)\n",
    "\n",
    "# converts into a tensor of numerical token IDs -> [2,21,45,.....,3]\n",
    "def text_to_tensor(text, vocab, tokenizer):\n",
    "    tokens = [vocab[\"<bos>\"]] + [vocab[token] if token in vocab else vocab[\"<unk>\"] for token in tokenizer(text)] + [vocab[\"<eos>\"]]\n",
    "    return torch.tensor(tokens, dtype=torch.long)\n",
    "\n",
    "\n",
    "def collate_fn(batch):\n",
    "    src_batch, tgt_batch = [], []\n",
    "    for src_text, tgt_text in batch:\n",
    "        src_batch.append(text_to_tensor(src_text, en_vocab, en_tokenizer))\n",
    "        tgt_batch.append(text_to_tensor(tgt_text, de_vocab, de_tokenizer))\n",
    "\n",
    "    # --- REVISED PADDING ---\n",
    "    # Find max length for source batch\n",
    "    max_len_src = max(len(seq) for seq in src_batch)\n",
    "    # Find max length for target batch\n",
    "    max_len_tgt = max(len(seq) for seq in tgt_batch)\n",
    "\n",
    "    # Pad source sequences to max_len_src\n",
    "    src_batch_padded = [\n",
    "        torch.cat([seq, torch.full((max_len_src - len(seq),), en_vocab[\"<pad>\"], dtype=torch.long)])\n",
    "        for seq in src_batch\n",
    "    ]\n",
    "    # Pad target sequences to max_len_tgt\n",
    "    tgt_batch_padded = [\n",
    "        torch.cat([seq, torch.full((max_len_tgt - len(seq),), de_vocab[\"<pad>\"], dtype=torch.long)])\n",
    "        for seq in tgt_batch\n",
    "    ]\n",
    "\n",
    "    src_batch_stacked = torch.stack(src_batch_padded)\n",
    "    tgt_batch_stacked = torch.stack(tgt_batch_padded)\n",
    "\n",
    "    return src_batch_stacked, tgt_batch_stacked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized sample: ['This', 'is', 'an', 'example', 'sentence', '.']\n",
      "Train Data: 23200 samples\n",
      "Validation Data: 2900 samples\n",
      "Test Data: 2901 samples\n",
      "Loaded first 2 samples: [('Starting a game of hair hockey between two men.', 'Es beginnt ein haariges Hockeyspiel zwischen zwei Männern.'), ('Two men being watched by many, wearing no pants or shirt, one having tattoos and wearing some kind of headgear.', 'Zwei Männer ohne Hosen und Oberteil, von denen einer tätowiert ist und eine Art Kopfbedeckung trägt, werden von vielen Personen angeschaut.')]\n"
     ]
    }
   ],
   "source": [
    "# Tokenizers\n",
    "# Tokenizer converts text into a list of tokens (words)\n",
    "en_tokenizer = get_tokenizer(\"spacy\", language = \"en_core_web_sm\") # Small English tokenizer model\n",
    "de_tokenizer = get_tokenizer(\"spacy\", language = \"de_core_news_sm\") # Small German tokenizer model\n",
    "\n",
    "# Example:\n",
    "sample_text = \"This is an example sentence.\"\n",
    "print(\"Tokenized sample:\", en_tokenizer(sample_text))\n",
    "# Expected Output: ['This', 'is', 'an', 'example', 'sentence', '.']\n",
    "\n",
    "# Loading the data\n",
    "full_train_data = list(Multi30k(split = 'train', language_pair = ('en', 'de'))) # Multi30K is a dataset for English-German translation.\n",
    "# Shuffle the data to ensure randomness\n",
    "random.shuffle(full_train_data)\n",
    "\n",
    "# Split dataset into train, validation, and test (80-10-10 split)\n",
    "train_size = int(0.8 * len(full_train_data))  # 80% for training\n",
    "val_size = int(0.1 * len(full_train_data))    # 10% for validation\n",
    "test_size = len(full_train_data) - train_size - val_size  # Remaining 10% for testing\n",
    "\n",
    "# Create subsets\n",
    "train_data = full_train_data[:train_size]\n",
    "val_data = full_train_data[train_size:train_size + val_size]\n",
    "test_data = full_train_data[train_size + val_size:]\n",
    "\n",
    "print(f\"Train Data: {len(train_data)} samples\")\n",
    "print(f\"Validation Data: {len(val_data)} samples\")\n",
    "print(f\"Test Data: {len(test_data)} samples\")\n",
    "\n",
    "\n",
    "print(\"Loaded first 2 samples:\", train_data[:2])  # Print first two samples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "4G5NJDi3Sx2t"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "F5DXx3sARDHl",
    "outputId": "2f1db1f6-a35d-4c43-8ddb-5b5f6144f5c9"
   },
   "outputs": [],
   "source": [
    "num_epochs = 200\n",
    "clip = 5 # Gradient Clipping to prevent exploding gradients\n",
    "embed_size = 512\n",
    "num_layers=4\n",
    "forward_expansion=4\n",
    "heads=8\n",
    "dropout=0.1\n",
    "device=device\n",
    "max_length=256\n",
    "batch_size = 256\n",
    "lr=0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NGBii_2dRNgp",
    "outputId": "90e86d37-1a6d-446a-b3ed-833392bd725e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of English vocab is 9804 and German vocab is 16847 for 23200 samples\n",
      "First Source batch shape : torch.Size([256, 31]) ; First Target Batch shape : torch.Size([256, 28])\n",
      "German sentence: Es beginnt ein haariges Hockeyspiel zwischen zwei Männern.\n",
      "Tokenized: ['Es', 'beginnt', 'ein', 'haariges', 'Hockeyspiel', 'zwischen', 'zwei', 'Männern', '.']\n",
      "Token IDs: [21, 83, 255, 31, 84, 22, 95, 4]\n"
     ]
    }
   ],
   "source": [
    "# Build vocab for the data i.e. all unique tokens(text) to Uniques IDs from the data\n",
    "en_vocab = build_vocab_from_iterator(yield_tokens(train_data, en_tokenizer, lang = \"en\"), specials=[\"<unk>\", \"<pad>\", \"<bos>\", \"<eos>\"])\n",
    "de_vocab = build_vocab_from_iterator(yield_tokens(train_data, de_tokenizer, lang = \"de\"), specials=[\"<unk>\", \"<pad>\", \"<bos>\", \"<eos>\"])\n",
    "\n",
    "# Set unknown token index (handles words not in vocab)\n",
    "en_vocab.set_default_index(en_vocab[\"<unk>\"])\n",
    "de_vocab.set_default_index(de_vocab[\"<unk>\"])\n",
    "\n",
    "print(f\"Length of English vocab is {len(en_vocab)} and German vocab is {len(de_vocab)} for {len(train_data)} samples\")\n",
    "\n",
    "# DataLoader handles **shuffling**, **batching**, and **efficient loading**.\n",
    "train_dataloader = DataLoader(train_data, batch_size = batch_size, collate_fn = collate_fn)\n",
    "val_dataloader = DataLoader(val_data, batch_size = batch_size, collate_fn = collate_fn)\n",
    "\n",
    "\n",
    "for src_batch, tgt_batch in train_dataloader:\n",
    "    print(f\"First Source batch shape : {src_batch.shape} ; First Target Batch shape : {tgt_batch.shape}\")\n",
    "    break\n",
    "\n",
    "\n",
    "sample_german_sentence = train_data[0][1]  # Get first German sentence\n",
    "print(\"German sentence:\", sample_german_sentence)\n",
    "print(\"Tokenized:\", de_tokenizer(sample_german_sentence))\n",
    "tokens = de_tokenizer(\"Zwei junge weiße Männer sind im Freien .\")\n",
    "print(\"Token IDs:\", [de_vocab[token] for token in tokens])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, dataloader, optimizer, scheduler, loss_fn, device):\n",
    "    model.train() # Setting the model to train mode\n",
    "    epoch_loss = 0\n",
    "\n",
    "    # dataloader = [(32,24), #English\n",
    "    #                (32,24) #German]\n",
    "    for batch_idx, (src,tgt) in enumerate(dataloader):\n",
    "        src, tgt = src.to(device), tgt.to(device)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Target input (remove last token) and target output (remove first token) # Teacher forcing strategy for seq-to-seq models\n",
    "        tgt_input = tgt[:,:-1] # Input to decoder # (32,23)\n",
    "        tgt_output = tgt[:,1:] # Target decoder output # (32,23)\n",
    "\n",
    "        # Forward pass\n",
    "        output = model(src, tgt_input) # (32, 23, 17000) -> (Batch_Size, Max_Target_Seq_Len - 1, Target_Vocab_Size)\n",
    "\n",
    "\n",
    "        # Reshape output to match loss function expectations\n",
    "        output = output.reshape(-1, output.shape[-1])  # (736, 17000)-> [batch*seq_len, vocab_size]\n",
    "        tgt_output = tgt_output.reshape(-1) # (736,) -> [batch*seq_len]\n",
    "\n",
    "        # Compute loss\n",
    "        loss = loss_fn(output, tgt_output)\n",
    "        loss.backward()\n",
    "\n",
    "        # Gradient Clipping to ptevent exploding gradients\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=clip)\n",
    "\n",
    "        # Update weights\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "        # # Print loss every 100 batches\n",
    "        # if batch_idx % 100 == 0:\n",
    "        #     print(f\"Batch [{batch_idx}/{len(train_dataloader)}], Loss: {loss.item():.4f}\")\n",
    "\n",
    "    return epoch_loss / len(dataloader)\n",
    "\n",
    "\n",
    "\n",
    "def evaluate(model, dataloader, loss_fn, device):\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    epoch_loss = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for src, tgt in dataloader:\n",
    "            src, tgt = src.to(device), tgt.to(device)\n",
    "\n",
    "\n",
    "            tgt_input = tgt[:, :-1]  # Input to decoder (without <eos>)\n",
    "            tgt_output = tgt[:, 1:]  # Target output (without <bos>)\n",
    "\n",
    "\n",
    "            output = model(src, tgt_input)\n",
    "\n",
    "            # Reshape output for loss computation\n",
    "            output = output.reshape(-1, output.shape[-1])\n",
    "            tgt_output = tgt_output.reshape(-1)\n",
    "\n",
    "            loss = loss_fn(output, tgt_output)\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "    return epoch_loss / len(dataloader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "KAd76Z1BY2V6"
   },
   "outputs": [],
   "source": [
    "src_pad_idx = en_vocab[\"<pad>\"]\n",
    "trg_pad_idx = de_vocab[\"<pad>\"]\n",
    "src_vocab_size = len(en_vocab)\n",
    "trg_vocab_size = len(de_vocab)\n",
    "\n",
    "# Define Transformer model\n",
    "model = Transformer(\n",
    "    src_vocab_size,\n",
    "    trg_vocab_size,\n",
    "    src_pad_idx,\n",
    "    trg_pad_idx,\n",
    "    embed_size=embed_size,\n",
    "    num_layers=num_layers,\n",
    "    forward_expansion=forward_expansion,\n",
    "    heads=heads,\n",
    "    dropout=dropout,\n",
    "    device=device,\n",
    "    max_length=max_length,\n",
    ").to(device)\n",
    "\n",
    "loss_fn = torch.nn.CrossEntropyLoss(ignore_index=trg_pad_idx, label_smoothing=0.1)\n",
    "\n",
    "optimizer = optim.AdamW(\n",
    "    model.parameters(),\n",
    "    lr=lr,            # Initial learning rate\n",
    "    betas=(0.9, 0.98),   # β1 = 0.9, β2 = 0.98\n",
    "    eps=1e-9,             # Small epsilon value for numerical stability\n",
    "    weight_decay = 0.01\n",
    ")\n",
    "\n",
    "import math\n",
    "\n",
    "class InverseSqrtLR(optim.lr_scheduler.LambdaLR):\n",
    "    def __init__(self, optimizer, d_model, warmup_steps):\n",
    "        self.d_model = d_model\n",
    "        self.warmup_steps = warmup_steps\n",
    "        super().__init__(optimizer, self.lr_lambda)\n",
    "\n",
    "    def lr_lambda(self, step_num):\n",
    "        step_num = max(step_num, 1)  # Ensure step_num is at least 1\n",
    "        return (self.d_model ** -0.5) * min(step_num ** -0.5, step_num * (self.warmup_steps ** -1.5))\n",
    "\n",
    "# Set up the scheduler with warm-up steps\n",
    "warmup_steps = 1600\n",
    "scheduler = InverseSqrtLR(optimizer, d_model=512, warmup_steps=warmup_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "BY301Ze2Rrzp"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss: 76.784 | Validation Loss: 72.050 Time: 0m 19s\n",
      "Model saved to best_transformer_model_20250720-161409.pth!\n",
      "Epoch 2: Train Loss: 74.060 | Validation Loss: 66.634 Time: 0m 19s\n",
      "Model saved to best_transformer_model_20250720-161409.pth!\n",
      "Epoch 3: Train Loss: 69.525 | Validation Loss: 59.579 Time: 0m 19s\n",
      "Model saved to best_transformer_model_20250720-161409.pth!\n",
      "Epoch 4: Train Loss: 63.565 | Validation Loss: 51.568 Time: 0m 19s\n",
      "Model saved to best_transformer_model_20250720-161409.pth!\n",
      "Epoch 5: Train Loss: 56.840 | Validation Loss: 43.429 Time: 0m 19s\n",
      "Model saved to best_transformer_model_20250720-161409.pth!\n",
      "Epoch 6: Train Loss: 50.015 | Validation Loss: 37.905 Time: 0m 19s\n",
      "Model saved to best_transformer_model_20250720-161409.pth!\n",
      "Epoch 7: Train Loss: 44.328 | Validation Loss: 32.508 Time: 0m 19s\n",
      "Model saved to best_transformer_model_20250720-161409.pth!\n",
      "Epoch 8: Train Loss: 39.505 | Validation Loss: 28.045 Time: 0m 19s\n",
      "Model saved to best_transformer_model_20250720-161409.pth!\n",
      "Epoch 9: Train Loss: 35.525 | Validation Loss: 24.538 Time: 0m 19s\n",
      "Model saved to best_transformer_model_20250720-161409.pth!\n",
      "Epoch 10: Train Loss: 32.347 | Validation Loss: 21.839 Time: 0m 19s\n",
      "Model saved to best_transformer_model_20250720-161409.pth!\n",
      "Epoch 11: Train Loss: 29.803 | Validation Loss: 19.545 Time: 0m 19s\n",
      "Model saved to best_transformer_model_20250720-161409.pth!\n",
      "Epoch 12: Train Loss: 27.664 | Validation Loss: 17.819 Time: 0m 19s\n",
      "Model saved to best_transformer_model_20250720-161409.pth!\n",
      "Epoch 13: Train Loss: 25.870 | Validation Loss: 16.231 Time: 0m 19s\n",
      "Model saved to best_transformer_model_20250720-161409.pth!\n",
      "Epoch 14: Train Loss: 24.312 | Validation Loss: 15.211 Time: 0m 19s\n",
      "Model saved to best_transformer_model_20250720-161409.pth!\n",
      "Epoch 15: Train Loss: 23.002 | Validation Loss: 14.156 Time: 0m 19s\n",
      "Model saved to best_transformer_model_20250720-161409.pth!\n",
      "Epoch 16: Train Loss: 21.809 | Validation Loss: 13.367 Time: 0m 19s\n",
      "Model saved to best_transformer_model_20250720-161409.pth!\n",
      "Epoch 17: Train Loss: 20.779 | Validation Loss: 12.551 Time: 0m 19s\n",
      "Model saved to best_transformer_model_20250720-161409.pth!\n",
      "Epoch 18: Train Loss: 19.812 | Validation Loss: 12.129 Time: 0m 19s\n",
      "Model saved to best_transformer_model_20250720-161409.pth!\n",
      "Epoch 19: Train Loss: 18.941 | Validation Loss: 11.537 Time: 0m 19s\n",
      "Model saved to best_transformer_model_20250720-161409.pth!\n",
      "Epoch 20: Train Loss: 18.247 | Validation Loss: 11.085 Time: 0m 19s\n",
      "Model saved to best_transformer_model_20250720-161409.pth!\n",
      "Epoch 21: Train Loss: 17.617 | Validation Loss: 10.736 Time: 0m 19s\n",
      "Model saved to best_transformer_model_20250720-161409.pth!\n",
      "Epoch 22: Train Loss: 17.076 | Validation Loss: 10.450 Time: 0m 19s\n",
      "Model saved to best_transformer_model_20250720-161409.pth!\n",
      "Epoch 23: Train Loss: 16.591 | Validation Loss: 10.228 Time: 0m 19s\n",
      "Model saved to best_transformer_model_20250720-161409.pth!\n",
      "Epoch 24: Train Loss: 16.169 | Validation Loss: 9.997 Time: 0m 19s\n",
      "Model saved to best_transformer_model_20250720-161409.pth!\n",
      "Epoch 25: Train Loss: 15.750 | Validation Loss: 9.722 Time: 0m 19s\n",
      "Model saved to best_transformer_model_20250720-161409.pth!\n",
      "Epoch 26: Train Loss: 15.398 | Validation Loss: 9.486 Time: 0m 19s\n",
      "Model saved to best_transformer_model_20250720-161409.pth!\n",
      "Epoch 27: Train Loss: 15.079 | Validation Loss: 9.405 Time: 0m 19s\n",
      "Model saved to best_transformer_model_20250720-161409.pth!\n",
      "Epoch 28: Train Loss: 14.766 | Validation Loss: 9.171 Time: 0m 19s\n",
      "Model saved to best_transformer_model_20250720-161409.pth!\n",
      "Epoch 29: Train Loss: 14.493 | Validation Loss: 9.039 Time: 0m 19s\n",
      "Model saved to best_transformer_model_20250720-161409.pth!\n",
      "Epoch 30: Train Loss: 14.256 | Validation Loss: 8.933 Time: 0m 19s\n",
      "Model saved to best_transformer_model_20250720-161409.pth!\n",
      "Epoch 31: Train Loss: 14.006 | Validation Loss: 8.873 Time: 0m 19s\n",
      "Model saved to best_transformer_model_20250720-161409.pth!\n",
      "Epoch 32: Train Loss: 13.784 | Validation Loss: 8.748 Time: 0m 19s\n",
      "Model saved to best_transformer_model_20250720-161409.pth!\n",
      "Epoch 33: Train Loss: 13.576 | Validation Loss: 8.592 Time: 0m 19s\n",
      "Model saved to best_transformer_model_20250720-161409.pth!\n",
      "Epoch 34: Train Loss: 13.397 | Validation Loss: 8.550 Time: 0m 19s\n",
      "Model saved to best_transformer_model_20250720-161409.pth!\n",
      "Epoch 35: Train Loss: 13.213 | Validation Loss: 8.403 Time: 0m 19s\n",
      "Model saved to best_transformer_model_20250720-161409.pth!\n",
      "Epoch 36: Train Loss: 13.030 | Validation Loss: 8.386 Time: 0m 19s\n",
      "Model saved to best_transformer_model_20250720-161409.pth!\n",
      "Epoch 37: Train Loss: 12.853 | Validation Loss: 8.361 Time: 0m 19s\n",
      "Model saved to best_transformer_model_20250720-161409.pth!\n",
      "Epoch 38: Train Loss: 12.713 | Validation Loss: 8.246 Time: 0m 19s\n",
      "Model saved to best_transformer_model_20250720-161409.pth!\n",
      "Epoch 39: Train Loss: 12.559 | Validation Loss: 8.231 Time: 0m 19s\n",
      "Model saved to best_transformer_model_20250720-161409.pth!\n",
      "Epoch 40: Train Loss: 12.432 | Validation Loss: 8.092 Time: 0m 19s\n",
      "Model saved to best_transformer_model_20250720-161409.pth!\n",
      "Epoch 41: Train Loss: 12.296 | Validation Loss: 8.059 Time: 0m 19s\n",
      "Model saved to best_transformer_model_20250720-161409.pth!\n",
      "Epoch 42: Train Loss: 12.160 | Validation Loss: 8.003 Time: 0m 19s\n",
      "Model saved to best_transformer_model_20250720-161409.pth!\n",
      "Epoch 43: Train Loss: 12.033 | Validation Loss: 7.938 Time: 0m 19s\n",
      "Model saved to best_transformer_model_20250720-161409.pth!\n",
      "Epoch 44: Train Loss: 11.927 | Validation Loss: 7.908 Time: 0m 19s\n",
      "Model saved to best_transformer_model_20250720-161409.pth!\n",
      "Epoch 45: Train Loss: 11.806 | Validation Loss: 7.847 Time: 0m 19s\n",
      "Model saved to best_transformer_model_20250720-161409.pth!\n",
      "Epoch 46: Train Loss: 11.701 | Validation Loss: 7.832 Time: 0m 19s\n",
      "Model saved to best_transformer_model_20250720-161409.pth!\n",
      "Epoch 47: Train Loss: 11.592 | Validation Loss: 7.765 Time: 0m 19s\n",
      "Model saved to best_transformer_model_20250720-161409.pth!\n",
      "Epoch 48: Train Loss: 11.504 | Validation Loss: 7.688 Time: 0m 19s\n",
      "Model saved to best_transformer_model_20250720-161409.pth!\n",
      "Epoch 49: Train Loss: 11.407 | Validation Loss: 7.663 Time: 0m 19s\n",
      "Model saved to best_transformer_model_20250720-161409.pth!\n",
      "Epoch 50: Train Loss: 11.299 | Validation Loss: 7.610 Time: 0m 19s\n",
      "Model saved to best_transformer_model_20250720-161409.pth!\n",
      "Epoch 51: Train Loss: 11.204 | Validation Loss: 7.632 Time: 0m 19s\n",
      "Epoch 52: Train Loss: 11.126 | Validation Loss: 7.600 Time: 0m 19s\n",
      "Model saved to best_transformer_model_20250720-161409.pth!\n",
      "Epoch 53: Train Loss: 11.046 | Validation Loss: 7.533 Time: 0m 19s\n",
      "Model saved to best_transformer_model_20250720-161409.pth!\n",
      "Epoch 54: Train Loss: 10.965 | Validation Loss: 7.484 Time: 0m 19s\n",
      "Model saved to best_transformer_model_20250720-161409.pth!\n",
      "Epoch 55: Train Loss: 10.881 | Validation Loss: 7.478 Time: 0m 19s\n",
      "Model saved to best_transformer_model_20250720-161409.pth!\n",
      "Epoch 56: Train Loss: 10.803 | Validation Loss: 7.405 Time: 0m 19s\n",
      "Model saved to best_transformer_model_20250720-161409.pth!\n",
      "Epoch 57: Train Loss: 10.728 | Validation Loss: 7.429 Time: 0m 19s\n",
      "Epoch 58: Train Loss: 10.662 | Validation Loss: 7.401 Time: 0m 19s\n",
      "Model saved to best_transformer_model_20250720-161409.pth!\n",
      "Epoch 59: Train Loss: 10.588 | Validation Loss: 7.380 Time: 0m 19s\n",
      "Model saved to best_transformer_model_20250720-161409.pth!\n",
      "Epoch 60: Train Loss: 10.518 | Validation Loss: 7.327 Time: 0m 19s\n",
      "Model saved to best_transformer_model_20250720-161409.pth!\n",
      "Epoch 61: Train Loss: 10.449 | Validation Loss: 7.328 Time: 0m 19s\n",
      "Epoch 62: Train Loss: 10.399 | Validation Loss: 7.287 Time: 0m 19s\n",
      "Model saved to best_transformer_model_20250720-161409.pth!\n",
      "Epoch 63: Train Loss: 10.336 | Validation Loss: 7.267 Time: 0m 19s\n",
      "Model saved to best_transformer_model_20250720-161409.pth!\n",
      "Epoch 64: Train Loss: 10.271 | Validation Loss: 7.249 Time: 0m 19s\n",
      "Model saved to best_transformer_model_20250720-161409.pth!\n",
      "Epoch 65: Train Loss: 10.222 | Validation Loss: 7.231 Time: 0m 19s\n",
      "Model saved to best_transformer_model_20250720-161409.pth!\n",
      "Epoch 66: Train Loss: 10.154 | Validation Loss: 7.204 Time: 0m 19s\n",
      "Model saved to best_transformer_model_20250720-161409.pth!\n",
      "Epoch 67: Train Loss: 10.108 | Validation Loss: 7.188 Time: 0m 19s\n",
      "Model saved to best_transformer_model_20250720-161409.pth!\n",
      "Epoch 68: Train Loss: 10.043 | Validation Loss: 7.156 Time: 0m 19s\n",
      "Model saved to best_transformer_model_20250720-161409.pth!\n",
      "Epoch 69: Train Loss: 9.996 | Validation Loss: 7.147 Time: 0m 19s\n",
      "Model saved to best_transformer_model_20250720-161409.pth!\n",
      "Epoch 70: Train Loss: 9.952 | Validation Loss: 7.120 Time: 0m 19s\n",
      "Model saved to best_transformer_model_20250720-161409.pth!\n",
      "Epoch 71: Train Loss: 9.907 | Validation Loss: 7.098 Time: 0m 19s\n",
      "Model saved to best_transformer_model_20250720-161409.pth!\n",
      "Epoch 72: Train Loss: 9.849 | Validation Loss: 7.086 Time: 0m 19s\n",
      "Model saved to best_transformer_model_20250720-161409.pth!\n",
      "Epoch 73: Train Loss: 9.808 | Validation Loss: 7.038 Time: 0m 19s\n",
      "Model saved to best_transformer_model_20250720-161409.pth!\n",
      "Epoch 74: Train Loss: 9.764 | Validation Loss: 7.049 Time: 0m 19s\n",
      "Epoch 75: Train Loss: 9.717 | Validation Loss: 7.019 Time: 0m 19s\n",
      "Model saved to best_transformer_model_20250720-161409.pth!\n",
      "Epoch 76: Train Loss: 9.680 | Validation Loss: 7.010 Time: 0m 19s\n",
      "Model saved to best_transformer_model_20250720-161409.pth!\n",
      "Epoch 77: Train Loss: 9.629 | Validation Loss: 6.992 Time: 0m 19s\n",
      "Model saved to best_transformer_model_20250720-161409.pth!\n",
      "Epoch 78: Train Loss: 9.594 | Validation Loss: 6.991 Time: 0m 19s\n",
      "Model saved to best_transformer_model_20250720-161409.pth!\n",
      "Epoch 79: Train Loss: 9.562 | Validation Loss: 6.943 Time: 0m 19s\n",
      "Model saved to best_transformer_model_20250720-161409.pth!\n",
      "Epoch 80: Train Loss: 9.523 | Validation Loss: 6.941 Time: 0m 19s\n",
      "Model saved to best_transformer_model_20250720-161409.pth!\n",
      "Epoch 81: Train Loss: 9.491 | Validation Loss: 6.954 Time: 0m 19s\n",
      "Epoch 82: Train Loss: 9.448 | Validation Loss: 6.940 Time: 0m 19s\n",
      "Model saved to best_transformer_model_20250720-161409.pth!\n",
      "Epoch 83: Train Loss: 9.404 | Validation Loss: 6.936 Time: 0m 19s\n",
      "Model saved to best_transformer_model_20250720-161409.pth!\n",
      "Epoch 84: Train Loss: 9.379 | Validation Loss: 6.882 Time: 0m 19s\n",
      "Model saved to best_transformer_model_20250720-161409.pth!\n",
      "Epoch 85: Train Loss: 9.354 | Validation Loss: 6.881 Time: 0m 19s\n",
      "Model saved to best_transformer_model_20250720-161409.pth!\n",
      "Epoch 86: Train Loss: 9.314 | Validation Loss: 6.884 Time: 0m 19s\n",
      "Epoch 87: Train Loss: 9.282 | Validation Loss: 6.872 Time: 0m 19s\n",
      "Model saved to best_transformer_model_20250720-161409.pth!\n",
      "Epoch 88: Train Loss: 9.249 | Validation Loss: 6.858 Time: 0m 19s\n",
      "Model saved to best_transformer_model_20250720-161409.pth!\n",
      "Epoch 89: Train Loss: 9.219 | Validation Loss: 6.833 Time: 0m 19s\n",
      "Model saved to best_transformer_model_20250720-161409.pth!\n",
      "Epoch 90: Train Loss: 9.192 | Validation Loss: 6.818 Time: 0m 19s\n",
      "Model saved to best_transformer_model_20250720-161409.pth!\n",
      "Epoch 91: Train Loss: 9.163 | Validation Loss: 6.813 Time: 0m 19s\n",
      "Model saved to best_transformer_model_20250720-161409.pth!\n",
      "Epoch 92: Train Loss: 9.134 | Validation Loss: 6.818 Time: 0m 19s\n",
      "Epoch 93: Train Loss: 9.107 | Validation Loss: 6.790 Time: 0m 19s\n",
      "Model saved to best_transformer_model_20250720-161409.pth!\n",
      "Epoch 94: Train Loss: 9.073 | Validation Loss: 6.773 Time: 0m 19s\n",
      "Model saved to best_transformer_model_20250720-161409.pth!\n",
      "Epoch 95: Train Loss: 9.054 | Validation Loss: 6.778 Time: 0m 19s\n",
      "Epoch 96: Train Loss: 9.022 | Validation Loss: 6.778 Time: 0m 19s\n",
      "Epoch 97: Train Loss: 8.997 | Validation Loss: 6.767 Time: 0m 19s\n",
      "Model saved to best_transformer_model_20250720-161409.pth!\n",
      "Epoch 98: Train Loss: 8.976 | Validation Loss: 6.737 Time: 0m 19s\n",
      "Model saved to best_transformer_model_20250720-161409.pth!\n",
      "Epoch 99: Train Loss: 8.951 | Validation Loss: 6.742 Time: 0m 19s\n",
      "Epoch 100: Train Loss: 8.925 | Validation Loss: 6.746 Time: 0m 19s\n",
      "Epoch 101: Train Loss: 8.905 | Validation Loss: 6.738 Time: 0m 19s\n",
      "Epoch 102: Train Loss: 8.881 | Validation Loss: 6.709 Time: 0m 19s\n",
      "Model saved to best_transformer_model_20250720-161409.pth!\n",
      "Epoch 103: Train Loss: 8.860 | Validation Loss: 6.707 Time: 0m 19s\n",
      "Model saved to best_transformer_model_20250720-161409.pth!\n",
      "Epoch 104: Train Loss: 8.839 | Validation Loss: 6.696 Time: 0m 19s\n",
      "Model saved to best_transformer_model_20250720-161409.pth!\n",
      "Epoch 105: Train Loss: 8.809 | Validation Loss: 6.699 Time: 0m 19s\n",
      "Epoch 106: Train Loss: 8.793 | Validation Loss: 6.678 Time: 0m 19s\n",
      "Model saved to best_transformer_model_20250720-161409.pth!\n",
      "Epoch 107: Train Loss: 8.767 | Validation Loss: 6.672 Time: 0m 19s\n",
      "Model saved to best_transformer_model_20250720-161409.pth!\n",
      "Epoch 108: Train Loss: 8.746 | Validation Loss: 6.669 Time: 0m 19s\n",
      "Model saved to best_transformer_model_20250720-161409.pth!\n",
      "Epoch 109: Train Loss: 8.736 | Validation Loss: 6.667 Time: 0m 19s\n",
      "Model saved to best_transformer_model_20250720-161409.pth!\n",
      "Epoch 110: Train Loss: 8.717 | Validation Loss: 6.656 Time: 0m 19s\n",
      "Model saved to best_transformer_model_20250720-161409.pth!\n",
      "Epoch 111: Train Loss: 8.694 | Validation Loss: 6.635 Time: 0m 19s\n",
      "Model saved to best_transformer_model_20250720-161409.pth!\n",
      "Epoch 112: Train Loss: 8.670 | Validation Loss: 6.635 Time: 0m 19s\n",
      "Model saved to best_transformer_model_20250720-161409.pth!\n",
      "Epoch 113: Train Loss: 8.666 | Validation Loss: 6.635 Time: 0m 19s\n",
      "Model saved to best_transformer_model_20250720-161409.pth!\n",
      "Epoch 114: Train Loss: 8.638 | Validation Loss: 6.630 Time: 0m 19s\n",
      "Model saved to best_transformer_model_20250720-161409.pth!\n",
      "Epoch 115: Train Loss: 8.614 | Validation Loss: 6.612 Time: 0m 19s\n",
      "Model saved to best_transformer_model_20250720-161409.pth!\n",
      "Epoch 116: Train Loss: 8.601 | Validation Loss: 6.607 Time: 0m 19s\n",
      "Model saved to best_transformer_model_20250720-161409.pth!\n",
      "Epoch 117: Train Loss: 8.582 | Validation Loss: 6.595 Time: 0m 19s\n",
      "Model saved to best_transformer_model_20250720-161409.pth!\n",
      "Epoch 118: Train Loss: 8.571 | Validation Loss: 6.607 Time: 0m 19s\n",
      "Epoch 119: Train Loss: 8.547 | Validation Loss: 6.605 Time: 0m 19s\n",
      "Epoch 120: Train Loss: 8.530 | Validation Loss: 6.596 Time: 0m 19s\n",
      "Epoch 121: Train Loss: 8.516 | Validation Loss: 6.588 Time: 0m 19s\n",
      "Model saved to best_transformer_model_20250720-161409.pth!\n",
      "Epoch 122: Train Loss: 8.499 | Validation Loss: 6.558 Time: 0m 19s\n",
      "Model saved to best_transformer_model_20250720-161409.pth!\n",
      "Epoch 123: Train Loss: 8.490 | Validation Loss: 6.569 Time: 0m 19s\n",
      "Epoch 124: Train Loss: 8.469 | Validation Loss: 6.574 Time: 0m 19s\n",
      "Epoch 125: Train Loss: 8.457 | Validation Loss: 6.573 Time: 0m 19s\n",
      "Epoch 126: Train Loss: 8.441 | Validation Loss: 6.558 Time: 0m 19s\n",
      "Epoch 127: Train Loss: 8.424 | Validation Loss: 6.549 Time: 0m 19s\n",
      "Model saved to best_transformer_model_20250720-161409.pth!\n",
      "Epoch 128: Train Loss: 8.414 | Validation Loss: 6.533 Time: 0m 19s\n",
      "Model saved to best_transformer_model_20250720-161409.pth!\n",
      "Epoch 129: Train Loss: 8.395 | Validation Loss: 6.535 Time: 0m 19s\n",
      "Epoch 130: Train Loss: 8.378 | Validation Loss: 6.544 Time: 0m 19s\n",
      "Epoch 131: Train Loss: 8.365 | Validation Loss: 6.520 Time: 0m 19s\n",
      "Model saved to best_transformer_model_20250720-161409.pth!\n",
      "Epoch 132: Train Loss: 8.350 | Validation Loss: 6.517 Time: 0m 19s\n",
      "Model saved to best_transformer_model_20250720-161409.pth!\n",
      "Epoch 133: Train Loss: 8.343 | Validation Loss: 6.494 Time: 0m 19s\n",
      "Model saved to best_transformer_model_20250720-161409.pth!\n",
      "Epoch 134: Train Loss: 8.332 | Validation Loss: 6.525 Time: 0m 19s\n",
      "Epoch 135: Train Loss: 8.309 | Validation Loss: 6.495 Time: 0m 19s\n",
      "Epoch 136: Train Loss: 8.303 | Validation Loss: 6.510 Time: 0m 19s\n",
      "Epoch 137: Train Loss: 8.286 | Validation Loss: 6.503 Time: 0m 19s\n",
      "Epoch 138: Train Loss: 8.274 | Validation Loss: 6.508 Time: 0m 19s\n",
      "Epoch 139: Train Loss: 8.261 | Validation Loss: 6.503 Time: 0m 19s\n",
      "Epoch 140: Train Loss: 8.244 | Validation Loss: 6.485 Time: 0m 19s\n",
      "Model saved to best_transformer_model_20250720-161409.pth!\n",
      "Epoch 141: Train Loss: 8.241 | Validation Loss: 6.480 Time: 0m 19s\n",
      "Model saved to best_transformer_model_20250720-161409.pth!\n",
      "Epoch 142: Train Loss: 8.224 | Validation Loss: 6.486 Time: 0m 19s\n",
      "Epoch 143: Train Loss: 8.213 | Validation Loss: 6.477 Time: 0m 19s\n",
      "Model saved to best_transformer_model_20250720-161409.pth!\n",
      "Epoch 144: Train Loss: 8.204 | Validation Loss: 6.475 Time: 0m 19s\n",
      "Model saved to best_transformer_model_20250720-161409.pth!\n",
      "Epoch 145: Train Loss: 8.190 | Validation Loss: 6.476 Time: 0m 19s\n",
      "Epoch 146: Train Loss: 8.179 | Validation Loss: 6.461 Time: 0m 19s\n",
      "Model saved to best_transformer_model_20250720-161409.pth!\n",
      "Epoch 147: Train Loss: 8.167 | Validation Loss: 6.463 Time: 0m 19s\n",
      "Epoch 148: Train Loss: 8.160 | Validation Loss: 6.462 Time: 0m 19s\n",
      "Epoch 149: Train Loss: 8.147 | Validation Loss: 6.458 Time: 0m 19s\n",
      "Model saved to best_transformer_model_20250720-161409.pth!\n",
      "Epoch 150: Train Loss: 8.128 | Validation Loss: 6.452 Time: 0m 19s\n",
      "Model saved to best_transformer_model_20250720-161409.pth!\n",
      "Epoch 151: Train Loss: 8.125 | Validation Loss: 6.450 Time: 0m 19s\n",
      "Model saved to best_transformer_model_20250720-161409.pth!\n",
      "Epoch 152: Train Loss: 8.113 | Validation Loss: 6.450 Time: 0m 19s\n",
      "Model saved to best_transformer_model_20250720-161409.pth!\n",
      "Epoch 153: Train Loss: 8.105 | Validation Loss: 6.431 Time: 0m 19s\n",
      "Model saved to best_transformer_model_20250720-161409.pth!\n",
      "Epoch 154: Train Loss: 8.092 | Validation Loss: 6.428 Time: 0m 19s\n",
      "Model saved to best_transformer_model_20250720-161409.pth!\n",
      "Epoch 155: Train Loss: 8.081 | Validation Loss: 6.421 Time: 0m 19s\n",
      "Model saved to best_transformer_model_20250720-161409.pth!\n",
      "Epoch 156: Train Loss: 8.072 | Validation Loss: 6.433 Time: 0m 19s\n",
      "Epoch 157: Train Loss: 8.066 | Validation Loss: 6.422 Time: 0m 19s\n",
      "Epoch 158: Train Loss: 8.051 | Validation Loss: 6.404 Time: 0m 19s\n",
      "Model saved to best_transformer_model_20250720-161409.pth!\n",
      "Epoch 159: Train Loss: 8.040 | Validation Loss: 6.407 Time: 0m 19s\n",
      "Epoch 160: Train Loss: 8.036 | Validation Loss: 6.409 Time: 0m 19s\n",
      "Epoch 161: Train Loss: 8.020 | Validation Loss: 6.415 Time: 0m 19s\n",
      "Epoch 162: Train Loss: 8.010 | Validation Loss: 6.410 Time: 0m 19s\n",
      "Epoch 163: Train Loss: 8.005 | Validation Loss: 6.406 Time: 0m 19s\n",
      "Epoch 164: Train Loss: 7.995 | Validation Loss: 6.402 Time: 0m 19s\n",
      "Model saved to best_transformer_model_20250720-161409.pth!\n",
      "Epoch 165: Train Loss: 7.983 | Validation Loss: 6.384 Time: 0m 19s\n",
      "Model saved to best_transformer_model_20250720-161409.pth!\n",
      "Epoch 166: Train Loss: 7.978 | Validation Loss: 6.393 Time: 0m 19s\n",
      "Epoch 167: Train Loss: 7.969 | Validation Loss: 6.381 Time: 0m 19s\n",
      "Model saved to best_transformer_model_20250720-161409.pth!\n",
      "Epoch 168: Train Loss: 7.959 | Validation Loss: 6.389 Time: 0m 19s\n",
      "Epoch 169: Train Loss: 7.951 | Validation Loss: 6.385 Time: 0m 19s\n",
      "Epoch 170: Train Loss: 7.939 | Validation Loss: 6.375 Time: 0m 19s\n",
      "Model saved to best_transformer_model_20250720-161409.pth!\n",
      "Epoch 171: Train Loss: 7.932 | Validation Loss: 6.371 Time: 0m 19s\n",
      "Model saved to best_transformer_model_20250720-161409.pth!\n",
      "Epoch 172: Train Loss: 7.923 | Validation Loss: 6.376 Time: 0m 19s\n",
      "Epoch 173: Train Loss: 7.921 | Validation Loss: 6.369 Time: 0m 19s\n",
      "Model saved to best_transformer_model_20250720-161409.pth!\n",
      "Epoch 174: Train Loss: 7.910 | Validation Loss: 6.373 Time: 0m 19s\n",
      "Epoch 175: Train Loss: 7.901 | Validation Loss: 6.355 Time: 0m 19s\n",
      "Model saved to best_transformer_model_20250720-161409.pth!\n",
      "Epoch 176: Train Loss: 7.894 | Validation Loss: 6.362 Time: 0m 19s\n",
      "Epoch 177: Train Loss: 7.888 | Validation Loss: 6.353 Time: 0m 19s\n",
      "Model saved to best_transformer_model_20250720-161409.pth!\n",
      "Epoch 178: Train Loss: 7.879 | Validation Loss: 6.358 Time: 0m 19s\n",
      "Epoch 179: Train Loss: 7.871 | Validation Loss: 6.350 Time: 0m 19s\n",
      "Model saved to best_transformer_model_20250720-161409.pth!\n",
      "Epoch 180: Train Loss: 7.866 | Validation Loss: 6.356 Time: 0m 19s\n",
      "Epoch 181: Train Loss: 7.854 | Validation Loss: 6.345 Time: 0m 19s\n",
      "Model saved to best_transformer_model_20250720-161409.pth!\n",
      "Epoch 182: Train Loss: 7.845 | Validation Loss: 6.338 Time: 0m 19s\n",
      "Model saved to best_transformer_model_20250720-161409.pth!\n",
      "Epoch 183: Train Loss: 7.835 | Validation Loss: 6.332 Time: 0m 19s\n",
      "Model saved to best_transformer_model_20250720-161409.pth!\n",
      "Epoch 184: Train Loss: 7.830 | Validation Loss: 6.330 Time: 0m 19s\n",
      "Model saved to best_transformer_model_20250720-161409.pth!\n",
      "Epoch 185: Train Loss: 7.822 | Validation Loss: 6.333 Time: 0m 19s\n",
      "Epoch 186: Train Loss: 7.815 | Validation Loss: 6.329 Time: 0m 19s\n",
      "Model saved to best_transformer_model_20250720-161409.pth!\n",
      "Epoch 187: Train Loss: 7.803 | Validation Loss: 6.323 Time: 0m 19s\n",
      "Model saved to best_transformer_model_20250720-161409.pth!\n",
      "Epoch 188: Train Loss: 7.802 | Validation Loss: 6.328 Time: 0m 19s\n",
      "Epoch 189: Train Loss: 7.792 | Validation Loss: 6.325 Time: 0m 19s\n",
      "Epoch 190: Train Loss: 7.787 | Validation Loss: 6.322 Time: 0m 19s\n",
      "Model saved to best_transformer_model_20250720-161409.pth!\n",
      "Epoch 191: Train Loss: 7.779 | Validation Loss: 6.314 Time: 0m 19s\n",
      "Model saved to best_transformer_model_20250720-161409.pth!\n",
      "Epoch 192: Train Loss: 7.768 | Validation Loss: 6.306 Time: 0m 19s\n",
      "Model saved to best_transformer_model_20250720-161409.pth!\n",
      "Epoch 193: Train Loss: 7.769 | Validation Loss: 6.308 Time: 0m 19s\n",
      "Epoch 194: Train Loss: 7.763 | Validation Loss: 6.313 Time: 0m 19s\n",
      "Epoch 195: Train Loss: 7.753 | Validation Loss: 6.305 Time: 0m 19s\n",
      "Model saved to best_transformer_model_20250720-161409.pth!\n",
      "Epoch 196: Train Loss: 7.747 | Validation Loss: 6.302 Time: 0m 19s\n",
      "Model saved to best_transformer_model_20250720-161409.pth!\n",
      "Epoch 197: Train Loss: 7.736 | Validation Loss: 6.308 Time: 0m 19s\n",
      "Epoch 198: Train Loss: 7.729 | Validation Loss: 6.295 Time: 0m 19s\n",
      "Model saved to best_transformer_model_20250720-161409.pth!\n",
      "Epoch 199: Train Loss: 7.728 | Validation Loss: 6.295 Time: 0m 19s\n",
      "Model saved to best_transformer_model_20250720-161409.pth!\n",
      "Epoch 200: Train Loss: 7.714 | Validation Loss: 6.292 Time: 0m 19s\n",
      "Model saved to best_transformer_model_20250720-161409.pth!\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Final best model successfully uploaded to: s3://spajjuri-transformers/transformer-model-v2/best_transformer_model_20250720-161409.pth\n"
     ]
    }
   ],
   "source": [
    "# Define the directory path\n",
    "import os\n",
    "import datetime\n",
    "\n",
    "# model_dir = \"/content/drive/My Drive/Colab Notebooks/models\"\n",
    "# Create the directory if it doesn't exist\n",
    "sess = sagemaker.Session()\n",
    "role = sagemaker.get_execution_role()  # IAM role for accessing SageMaker\n",
    "\n",
    "# bucket = sess.default_bucket()  # S3 bucket for storing models\n",
    "bucket = \"spajjuri-transformers\"  # S3 bucket for storing models\n",
    "s3_model_prefix = \"transformer-model-v2\"\n",
    "timestamp = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "local_model_path = f\"best_transformer_model_{timestamp}.pth\"\n",
    "\n",
    "\n",
    "# Run training & evaluation\n",
    "best_valid_loss = float(\"inf\")\n",
    "train_losses = []\n",
    "valid_losses = []\n",
    "\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    start_time = time.time()\n",
    "\n",
    "    train_loss = train(model, train_dataloader, optimizer, scheduler, loss_fn, device)\n",
    "    valid_loss = evaluate(model, val_dataloader, loss_fn, device)\n",
    "\n",
    "\n",
    "    end_time = time.time()\n",
    "    epoch_mins, epoch_secs = divmod(int(end_time - start_time), 60)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}: Train Loss: {train_loss:.3f} | Validation Loss: {valid_loss:.3f} Time: {epoch_mins}m {epoch_secs}s\")\n",
    "\n",
    "    train_losses.append(train_loss)\n",
    "    valid_losses.append(valid_loss)\n",
    "\n",
    "    # # Save the model if validation loss improves\n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), local_model_path)\n",
    "        print(f\"Model saved to {local_model_path}!\")\n",
    "\n",
    "# --- End of Training ---\n",
    "plt.ioff() # Turn off interactive mode\n",
    "plt.show() # Keep the final plot displayed after training finishes\n",
    "\n",
    "# Plot Training & Validation Loss After Training\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(range(1, num_epochs+1), train_losses, label='Training Loss')\n",
    "plt.plot(range(1, num_epochs+1), valid_losses, label='Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training & Validation Loss Over Epochs')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "if os.path.exists(local_model_path):\n",
    "    s3_path = sess.upload_data(path=local_model_path, bucket=bucket, key_prefix=s3_model_prefix)\n",
    "    print(f\" Final best model successfully uploaded to: {s3_path}\")\n",
    "else:\n",
    "    print(\"No model was saved as validation loss did not improve.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "N7AaPMlVYyKM"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "VZSsecjNYx61"
   },
   "outputs": [],
   "source": [
    "def load_model(en_vocab, de_vocab, embed_size, num_layers, forward_expansion, heads, dropout, device, max_length, model_path):\n",
    "    print(\"Loading model...\")\n",
    "    \n",
    "    \n",
    "    checkpoint = torch.load(model_path, map_location=device)\n",
    "\n",
    "    model = Transformer(len(en_vocab), len(de_vocab), en_vocab[\"<pad>\"], de_vocab[\"<pad>\"], \n",
    "                        embed_size=embed_size,\n",
    "                        num_layers=num_layers,\n",
    "                        forward_expansion=forward_expansion,\n",
    "                        heads=heads,\n",
    "                        dropout=dropout,\n",
    "                        device=device,\n",
    "                        max_length=max_length).to(device)\n",
    "    \n",
    "        # Get the model's current embedding weights\n",
    "    model_state_dict = model.state_dict()\n",
    "    \n",
    "    # Resize encoder embedding if vocab size changed\n",
    "    if checkpoint[\"encoder.word_embedding.weight\"].shape != model_state_dict[\"encoder.word_embedding.weight\"].shape:\n",
    "        print(\"Resizing Encoder Embedding Layer...\")\n",
    "        old_embedding = checkpoint[\"encoder.word_embedding.weight\"]\n",
    "        new_embedding = model_state_dict[\"encoder.word_embedding.weight\"]\n",
    "        min_size = min(old_embedding.shape[0], new_embedding.shape[0])\n",
    "        new_embedding[:min_size, :] = old_embedding[:min_size, :]\n",
    "        checkpoint[\"encoder.word_embedding.weight\"] = new_embedding\n",
    "    \n",
    "    # Resize decoder embedding if vocab size changed\n",
    "    if checkpoint[\"decoder.word_embedding.weight\"].shape != model_state_dict[\"decoder.word_embedding.weight\"].shape:\n",
    "        print(\"Resizing Decoder Embedding Layer...\")\n",
    "        old_embedding = checkpoint[\"decoder.word_embedding.weight\"]\n",
    "        new_embedding = model_state_dict[\"decoder.word_embedding.weight\"]\n",
    "        min_size = min(old_embedding.shape[0], new_embedding.shape[0])\n",
    "        new_embedding[:min_size, :] = old_embedding[:min_size, :]\n",
    "        checkpoint[\"decoder.word_embedding.weight\"] = new_embedding\n",
    "    \n",
    "    # Resize output layer if vocab size changed\n",
    "    if checkpoint[\"decoder.fc_out.weight\"].shape != model_state_dict[\"decoder.fc_out.weight\"].shape:\n",
    "        print(\"Resizing Decoder Output Layer...\")\n",
    "        old_output = checkpoint[\"decoder.fc_out.weight\"]\n",
    "        new_output = model_state_dict[\"decoder.fc_out.weight\"]\n",
    "        min_size = min(old_output.shape[0], new_output.shape[0])\n",
    "        new_output[:min_size, :] = old_output[:min_size, :]\n",
    "        checkpoint[\"decoder.fc_out.weight\"] = new_output\n",
    "    \n",
    "    # Resize output bias if vocab size changed\n",
    "    if checkpoint[\"decoder.fc_out.bias\"].shape != model_state_dict[\"decoder.fc_out.bias\"].shape:\n",
    "        print(\"Resizing Decoder Output Bias...\")\n",
    "        old_bias = checkpoint[\"decoder.fc_out.bias\"]\n",
    "        new_bias = model_state_dict[\"decoder.fc_out.bias\"]\n",
    "        min_size = min(old_bias.shape[0], new_bias.shape[0])\n",
    "        new_bias[:min_size] = old_bias[:min_size]\n",
    "        checkpoint[\"decoder.fc_out.bias\"] = new_bias\n",
    "    \n",
    "    # Load the adjusted weights (ignore strict mismatches)\n",
    "    model.load_state_dict(checkpoint, strict=False)\n",
    "    model.to(device)\n",
    "    \n",
    "    return model\n",
    "\n",
    "def translate_sentence(model, sentence, src_vocab, trg_vocab, tokenizer, device, max_length=50):\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "\n",
    "    # Tokenize and convert to tensor safely\n",
    "    tokens = [src_vocab[\"<bos>\"]] + [\n",
    "        src_vocab[token] if token in src_vocab else src_vocab[\"<unk>\"] for token in tokenizer(sentence)\n",
    "    ] + [src_vocab[\"<eos>\"]]\n",
    "\n",
    "    # Debugging: Check if any tokens are out of vocab\n",
    "    for token in tokenizer(sentence):\n",
    "        if token not in src_vocab:\n",
    "            print(f\"WARNING: Token '{token}' not in vocab. Mapping to <unk>.\")\n",
    "\n",
    "    # Convert tokens to tensor and add batch dimension\n",
    "    sentence_tensor = torch.tensor(tokens, dtype=torch.long).unsqueeze(0).to(device)\n",
    "\n",
    "    print(f\"\\n Tokenized Sentence: {tokens} Sentence Tensor Shape: {sentence_tensor.shape}\")\n",
    "    # print(f\" Max Index in Sentence: {max(tokens)}, Vocab Size: {len(src_vocab)}\")\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # Encode the source sentence\n",
    "        src_mask = model.make_src_mask(sentence_tensor)\n",
    "        enc_src = model.encoder(sentence_tensor, src_mask)\n",
    "\n",
    "        # Initialize target sequence with <bos>\n",
    "        trg_indexes = [trg_vocab[\"<bos>\"]]\n",
    "\n",
    "        for i in range(max_length):\n",
    "            trg_tensor = torch.tensor(trg_indexes, dtype=torch.long).unsqueeze(0).to(device)\n",
    "            trg_mask = model.make_trg_mask(trg_tensor)\n",
    "\n",
    "            # Pass through the decoder\n",
    "            output = model.decoder(trg_tensor, enc_src, src_mask, trg_mask)\n",
    "\n",
    "            # Get the next token (greedy decoding)\n",
    "            next_word = output.argmax(2)[:, -1].item()\n",
    "            trg_indexes.append(next_word)\n",
    "\n",
    "            # Debugging: Print top predictions\n",
    "            probs = torch.softmax(output[:, -1, :], dim=-1)\n",
    "            top5 = torch.topk(probs, 5)\n",
    "            # print(f\"Step {i+1}: Next token: {next_word} ({trg_vocab.get_itos()[next_word]}) | Top5 Predictions: {top5.indices.tolist()}\")\n",
    "            print(f\"Generated Indexes : {trg_indexes} and shape {len(trg_indexes)}\")\n",
    "            # Stop if <eos> is generated\n",
    "            if next_word == trg_vocab[\"<eos>\"] or len(trg_indexes) == sentence_tensor.shape[1]:\n",
    "                print(\" Stopping as <eos> is generated.\")\n",
    "                break\n",
    "\n",
    "    translated_tokens = [trg_vocab.get_itos()[idx] for idx in trg_indexes]\n",
    "    print(f\" Translated Tokens: {translated_tokens[1:-1]}\")  # Excluding <bos> and <eos>\n",
    "    return translated_tokens[1:-1]  # Remove <bos> and <eos>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the best trained model\n",
    "model_path = local_model_path\n",
    "model = load_model(en_vocab, de_vocab, embed_size, num_layers, forward_expansion, heads, dropout, device, max_length, model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Rwx-vPd9OC2d",
    "outputId": "7cd7d8ea-9e47-43de-b67f-779958261fd9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Tokenized Sentence: [2, 5973, 6200, 1129, 6030, 760, 1529, 760, 2645, 3] Sentence Tensor Shape: torch.Size([1, 10])\n",
      "Generated Indexes : [2, 5] and shape 2\n",
      "Generated Indexes : [2, 5, 5] and shape 3\n",
      "Generated Indexes : [2, 5, 5, 5] and shape 4\n",
      "Generated Indexes : [2, 5, 5, 5, 5] and shape 5\n",
      "Generated Indexes : [2, 5, 5, 5, 5, 5] and shape 6\n",
      "Generated Indexes : [2, 5, 5, 5, 5, 5, 5] and shape 7\n",
      "Generated Indexes : [2, 5, 5, 5, 5, 5, 5, 5] and shape 8\n",
      "Generated Indexes : [2, 5, 5, 5, 5, 5, 5, 5, 5] and shape 9\n",
      "Generated Indexes : [2, 5, 5, 5, 5, 5, 5, 5, 5, 5] and shape 10\n",
      " Stopping as <eos> is generated.\n",
      " Translated Tokens: ['Ein', 'Ein', 'Ein', 'Ein', 'Ein', 'Ein', 'Ein', 'Ein']\n",
      "Translated Sentence: Ein Ein Ein Ein Ein Ein Ein Ein\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Example test sentence\n",
    "# test_sentence = \"A man is playing a guitar\"\n",
    "test_sentence = \"Good Morning! How do you do?\"\n",
    "\n",
    "translated_output = translate_sentence(model, test_sentence, en_vocab, de_vocab, en_tokenizer, device)\n",
    "print(\"Translated Sentence:\", \" \".join(translated_output))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QSgz4GzdZ9sS"
   },
   "outputs": [],
   "source": [
    "def compute_bleu(model, test_data, src_vocab, trg_vocab, src_tokenizer, trg_tokenizer, device):\n",
    "    model.eval()\n",
    "    references = []\n",
    "    hypotheses = []\n",
    "\n",
    "    for src_sentence, trg_sentence in test_data:\n",
    "        reference = [trg_tokenizer(trg_sentence)]  # Tokenize the ground-truth sentence\n",
    "        hypothesis = translate_sentence(model, src_sentence, src_vocab, trg_vocab, src_tokenizer, device)\n",
    "\n",
    "        references.append(reference)\n",
    "        hypotheses.append(hypothesis)\n",
    "\n",
    "    score = bleu_score(hypotheses, references)\n",
    "    return score\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Compute BLEU Score\n",
    "bleu = compute_bleu(model, test_data[:2], en_vocab, de_vocab, en_tokenizer, de_tokenizer, device)\n",
    "print(f\"BLEU Score: {bleu:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "conda_pytorch_p310",
   "language": "python",
   "name": "conda_pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
